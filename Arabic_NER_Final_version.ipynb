{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k6wzIBc0cJAr",
        "outputId": "f0a73fb3-a66d-4a33-cb9f-4e0fc8e29565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn_crfsuite)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (1.6.1)\n",
            "Collecting tabulate>=0.4.2 (from sklearn_crfsuite)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (3.6.0)\n",
            "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: tabulate, python-crfsuite, sklearn_crfsuite\n",
            "Successfully installed python-crfsuite-0.9.11 sklearn_crfsuite-0.5.0 tabulate-0.9.0\n",
            "Found existing installation: scipy 1.15.3\n",
            "Uninstalling scipy-1.15.3:\n",
            "  Successfully uninstalled scipy-1.15.3\n",
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-addons as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "fastai 2.7.19 requires scipy, which is not installed.\n",
            "jax 0.5.2 requires scipy>=1.11.1, which is not installed.\n",
            "scikit-learn 1.6.1 requires scipy>=1.6.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "numba 0.61.2 requires numpy<2.3,>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7242d153694f4dc185a8db123d64d44c",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m51.2/58.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scipy==1.10.1) (1.23.5)\n",
            "Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.10.1\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.12.0)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=2.0 (from tensorflow==2.12.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.12.0)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.12.0)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.12.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-pasta, gast, jaxlib, astunparse, jax, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.4.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 libclang-18.1.1 protobuf-4.25.7 tensorboard-2.12.3 tensorboard-data-server-0.7.2 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1\n",
            "Collecting tensorflow-addons==0.20.0\n",
            "  Downloading tensorflow_addons-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons==0.20.0) (25.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==0.20.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=f53f525ee4d10d05a62130819fe1ba99875b7ff3175112138910585101a0ee5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting camel_tools\n",
            "  Downloading camel_tools-1.5.6-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from pyarabic) (1.17.0)\n",
            "Collecting future (from camel_tools)\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting docopt (from camel_tools)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from camel_tools) (5.5.2)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from camel_tools) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from camel_tools) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from camel_tools) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from camel_tools) (1.6.1)\n",
            "Collecting dill (from camel_tools)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from camel_tools) (2.6.0+cpu)\n",
            "Collecting transformers<4.44.0,>=4.0 (from camel_tools)\n",
            "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting editdistance (from camel_tools)\n",
            "  Downloading editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from camel_tools) (2.32.3)\n",
            "Collecting emoji (from camel_tools)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pyrsistent (from camel_tools)\n",
            "  Downloading pyrsistent-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from camel_tools) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from camel_tools) (4.67.1)\n",
            "Collecting muddler (from camel_tools)\n",
            "  Downloading muddler-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting camel-kenlm>=2025.4.8 (from camel_tools)\n",
            "  Downloading camel-kenlm-2025.4.8.zip (556 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.5/556.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel_tools) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel_tools) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel_tools) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel_tools) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel_tools) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel_tools) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->camel_tools) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel_tools) (0.31.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel_tools) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel_tools) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel_tools) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel_tools) (0.5.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers<4.44.0,>=4.0->camel_tools)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->camel_tools) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->camel_tools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->camel_tools) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->camel_tools) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->camel_tools) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->camel_tools) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->camel_tools) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->camel_tools) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->camel_tools) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->camel_tools) (3.0.2)\n",
            "Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading camel_tools-1.5.6-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading muddler-0.1.3-py3-none-any.whl (16 kB)\n",
            "Downloading pyrsistent-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (120 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: camel-kenlm, docopt\n",
            "  Building wheel for camel-kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camel-kenlm: filename=camel_kenlm-2025.4.8-cp311-cp311-linux_x86_64.whl size=3455548 sha256=02c1a583e2d40ce12af7856450945441a07302213cf24c908b59938afe2a59d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/b9/62/8559aee1915ae6690fcc902a972a9ba0ff46d3ee67fea2aa44\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c6dc5a25f4a4dd63c19a380fae881069d6dc238c3ffc288f26f35a4ae68d2b57\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built camel-kenlm docopt\n",
            "Installing collected packages: docopt, camel-kenlm, pyrsistent, pyarabic, muddler, future, emoji, editdistance, dill, tokenizers, transformers, camel_tools\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "Successfully installed camel-kenlm-2025.4.8 camel_tools-1.5.6 dill-0.4.0 docopt-0.6.2 editdistance-0.8.1 emoji-2.14.1 future-1.0.0 muddler-0.1.3 pyarabic-0.6.15 pyrsistent-0.20.0 tokenizers-0.19.1 transformers-4.43.4\n",
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: et-xmlfile, openpyxl\n",
            "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip uninstall -y scipy numpy tensorflow tensorflow-addons\n",
        "!pip install numpy==1.23.5\n",
        "!pip install scipy==1.10.1\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install tensorflow-addons==0.20.0\n",
        "!pip install pandas\n",
        "!pip install seqeval\n",
        "!pip install pyarabic camel_tools\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxmOO78b1DC4",
        "outputId": "3723cd6d-05ae-4fc4-d627-0cd5566c6e90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout, Dense, TimeDistributed\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from seqeval.metrics import classification_report, f1_score, accuracy_score\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "from torch.utils.data import Dataset\n",
        "import pyarabic.araby as araby\n",
        "from camel_tools.utils.normalize import normalize_unicode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNSfJB40VKsW",
        "outputId": "bfc7f277-4def-4c21-9599-ca1a7cbc6cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVT09QghtPl"
      },
      "source": [
        "Lecture puis conversion du fichieer en format .csv pour faciliter les manipulations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "HQQQKTs35py6",
        "outputId": "42c3da23-8bcd-4d44-c64a-41a66737f5e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ee8df0b4-1147-4e4f-9082-1ca49627fea3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>فرانكفورت</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(د</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ب</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>أ)</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>أعلن</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>اتحاد</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>صناعة</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>السيارات</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>في</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee8df0b4-1147-4e4f-9082-1ca49627fea3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee8df0b4-1147-4e4f-9082-1ca49627fea3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee8df0b4-1147-4e4f-9082-1ca49627fea3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9c0d973f-e830-4c78-86d8-7e40693251e2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c0d973f-e830-4c78-86d8-7e40693251e2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9c0d973f-e830-4c78-86d8-7e40693251e2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           0      1    2\n",
              "0          0      1    2\n",
              "1  فرانكفورت  B-LOC  NaN\n",
              "2         (د      O  NaN\n",
              "3          ب      O  NaN\n",
              "4         أ)      O  NaN\n",
              "5       أعلن      O  NaN\n",
              "6      اتحاد  B-ORG  NaN\n",
              "7      صناعة  I-ORG  NaN\n",
              "8   السيارات  I-ORG  NaN\n",
              "9         في      O  NaN"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path= '/content/drive/MyDrive/Datasets/ANERCorp.xlsx'\n",
        "csv_path = \"/content/drive/MyDrive/Datasets/ANERCorp.csv\"\n",
        "df = pd.read_excel(path, header=None)\n",
        "df.to_csv(csv_path, index=False)\n",
        "data=pd.read_csv(csv_path, header=None)\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8wkYNLWh2ff"
      },
      "source": [
        "Renomage des headers en text/label puis suppression de l'ancien header (0/1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pkWo50MH5qBk",
        "outputId": "a9da2288-d153-4eeb-e5b5-0a8cc9fb6724"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-56b51940-699c-430b-91cc-def23e91bb7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>فرانكفورت</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(د</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ب</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>أ)</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>أعلن</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56b51940-699c-430b-91cc-def23e91bb7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56b51940-699c-430b-91cc-def23e91bb7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56b51940-699c-430b-91cc-def23e91bb7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cd275f90-8987-4882-8fae-b1adf8b3894e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd275f90-8987-4882-8fae-b1adf8b3894e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cd275f90-8987-4882-8fae-b1adf8b3894e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        text  label\n",
              "0  فرانكفورت  B-LOC\n",
              "1         (د      O\n",
              "2          ب      O\n",
              "3         أ)      O\n",
              "4       أعلن      O"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = df.drop(2, axis=1)\n",
        "data.columns = ['text', 'label']\n",
        "data.to_csv(csv_path, index=False)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJoox_ngBvyJ",
        "outputId": "45089dff-5a14-4aa0-98d0-8fbf61cfdf59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "O                 132029\n",
            "B-LOC               4429\n",
            "B-PERS              3598\n",
            "I-PERS              2831\n",
            "B-ORG               2023\n",
            "I-ORG               1379\n",
            "B-MISC              1115\n",
            "I-LOC                604\n",
            "I-MISC               539\n",
            "o                      4\n",
            "I-PRG                  2\n",
            "B-ERS                  2\n",
            "B-ORF                  1\n",
            "فيرسلاين               1\n",
            "IPERS                  1\n",
            "b-misc                 1\n",
            "‏                      1\n",
            "B-LOCI-PERS            1\n",
            "B-OEG                  1\n",
            "i-misc                 1\n",
            "Oالإصابة               1\n",
            "ونايفة</title>         1\n",
            "B-PERs                 1\n",
            "B-PRG                  1\n",
            "B-MSIC                 1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "count= data[\"label\"].value_counts()\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DiWTs1XkFHX"
      },
      "source": [
        "Calcule des classes distinctes ainsii que leur affichage pour mieux connaitre notre dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GBvyXJhD5qFf",
        "outputId": "7c070377-5fdc-4b59-b524-e3bbfa15225e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le nombre de classe est : {26}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'B-ERS',\n",
              " 'B-LOC',\n",
              " 'B-LOCI-PERS',\n",
              " 'B-MISC',\n",
              " 'B-MSIC',\n",
              " 'B-OEG',\n",
              " 'B-ORF',\n",
              " 'B-ORG',\n",
              " 'B-PERS',\n",
              " 'B-PERs',\n",
              " 'B-PRG',\n",
              " 'I-LOC',\n",
              " 'I-MISC',\n",
              " 'I-ORG',\n",
              " 'I-PERS',\n",
              " 'I-PRG',\n",
              " 'IPERS',\n",
              " 'O',\n",
              " 'Oالإصابة',\n",
              " 'b-misc',\n",
              " 'i-misc',\n",
              " nan,\n",
              " 'o',\n",
              " 'فيرسلاين',\n",
              " 'ونايفة</title>',\n",
              " '\\u200f'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = set(data['label'])\n",
        "print(\"Le nombre de classe est :\", {len(classes)})\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtygD4X_H5MU"
      },
      "outputs": [],
      "source": [
        "def prepare_data(data, word_col='text', label_col='label'):\n",
        "    sequences = []\n",
        "    words = []\n",
        "    tags = []\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        if pd.isna(row[word_col]) or pd.isna(row[label_col]):\n",
        "            if words and tags:\n",
        "                sequences.append((words, tags))\n",
        "                words = []\n",
        "                tags = []\n",
        "        else:\n",
        "            words.append(str(row[word_col]))\n",
        "            tags.append(str(row[label_col]))\n",
        "\n",
        "    if words and tags:\n",
        "        sequences.append((words, tags))\n",
        "\n",
        "    return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAxtRpjeRmuf"
      },
      "outputs": [],
      "source": [
        "def normalize_arabic_text(text):\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    text = normalize_unicode(text)\n",
        "\n",
        "    text = araby.strip_tashkeel(text)\n",
        "\n",
        "    text = araby.normalize_alef(text)\n",
        "\n",
        "    text = araby.normalize_hamza(text)\n",
        "\n",
        "    text = araby.normalize_ligature(text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vjmqxnScGt9h"
      },
      "outputs": [],
      "source": [
        "def get_word_features(word):\n",
        "    return {\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'word.is_year': bool(re.match(r'^[0-9]{4}$', word)),\n",
        "        'word.length': len(word),\n",
        "        'word.prefix1': word[:1] if len(word) > 0 else '',\n",
        "        'word.prefix2': word[:2] if len(word) > 1 else '',\n",
        "        'word.suffix1': word[-1:] if len(word) > 0 else '',\n",
        "        'word.suffix2': word[-2:] if len(word) > 1 else '',\n",
        "        'word.has_digit': any(c.isdigit() for c in word),\n",
        "        'word.has_punctuation': any(not c.isalnum() for c in word),\n",
        "        'word.has_alef': 'ا' in word,\n",
        "        'word.has_waw': 'و' in word,\n",
        "        'word.has_ya': 'ي' in word,\n",
        "        'word.has_ta_marbuta': 'ة' in word,\n",
        "        'word.has_alif_lam': 'ال' in word,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpoLWUPiGtr7"
      },
      "outputs": [],
      "source": [
        "def get_contextual_features(words, i):\n",
        "    features = {}\n",
        "\n",
        "    if i > 0:\n",
        "        prev_word = normalize_arabic_text(words[i-1])\n",
        "        features['prev_word'] = prev_word\n",
        "        if len(prev_word) >= 2:\n",
        "            features['prev_word.suffix2'] = prev_word[-2:]\n",
        "\n",
        "    if i < len(words) - 1:\n",
        "        next_word = normalize_arabic_text(words[i+1])\n",
        "        features['next_word'] = next_word\n",
        "        if len(next_word) >= 2:\n",
        "            features['next_word.prefix2'] = next_word[:2]\n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCCGYRMPIJI8"
      },
      "outputs": [],
      "source": [
        "def extract_features(words, i):\n",
        "    word = words[i]\n",
        "    normalized_word = normalize_arabic_text(word)\n",
        "\n",
        "    features = {}\n",
        "    features.update(get_word_features(normalized_word))\n",
        "    features.update(get_contextual_features(words, i))\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e0hBTorEJG4x"
      },
      "outputs": [],
      "source": [
        "def prepare_features(sequences):\n",
        "    X, y = [], []\n",
        "\n",
        "    for words, tags in sequences:\n",
        "        X_sent, y_sent = [], []\n",
        "        for i in range(len(words)):\n",
        "            X_sent.append(extract_features(words, i))\n",
        "            y_sent.append(tags[i])\n",
        "        X.append(X_sent)\n",
        "        y.append(y_sent)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl4eQWk-Ishn"
      },
      "outputs": [],
      "source": [
        "def train_crf_model(X_train, y_train, params=None):\n",
        "\n",
        "    if params is None:\n",
        "        params = {\n",
        "            'algorithm': 'lbfgs',\n",
        "            'c1': 0.1,  \n",
        "            'c2': 0.1, \n",
        "            'max_iterations': 100,\n",
        "            'all_possible_transitions': True\n",
        "        }\n",
        "\n",
        "    print(\"Début de l'entraînement du modèle CRF...\")\n",
        "    print(f\"Paramètres: {params}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    crf = sklearn_crfsuite.CRF(\n",
        "        algorithm=params['algorithm'],\n",
        "        c1=params['c1'],\n",
        "        c2=params['c2'],\n",
        "        max_iterations=params['max_iterations'],\n",
        "        all_possible_transitions=params['all_possible_transitions'],\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    crf.fit(X_train, y_train)\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Entraînement terminé en {training_time:.2f} secondes\")\n",
        "\n",
        "    return crf, training_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rjQx5RMaJmhj"
      },
      "outputs": [],
      "source": [
        "sequences = prepare_data(data)\n",
        "train_sequences, test_sequences = train_test_split(sequences, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train, y_train = prepare_features(train_sequences)\n",
        "X_test, y_test = prepare_features(test_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVU5EtJCunON",
        "outputId": "b44c820c-8468-4f49-d51d-e342c85b98cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Début de l'entraînement du modèle CRF...\n",
            "Paramètres: {'algorithm': 'lbfgs', 'c1': 0.1, 'c2': 0.1, 'max_iterations': 100, 'all_possible_transitions': True}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading training data to CRFsuite: 100%|██████████| 1204/1204 [00:01<00:00, 1079.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 61278\n",
            "Seconds required: 0.239\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.100000\n",
            "c2: 0.100000\n",
            "num_memories: 6\n",
            "max_iterations: 100\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=0.28  loss=90765.68 active=61003 feature_norm=1.00\n",
            "Iter 2   time=0.14  loss=88139.95 active=59165 feature_norm=0.99\n",
            "Iter 3   time=0.28  loss=68795.13 active=48330 feature_norm=1.78\n",
            "Iter 4   time=0.14  loss=64198.67 active=59284 feature_norm=1.80\n",
            "Iter 5   time=0.14  loss=59277.80 active=60036 feature_norm=1.83\n",
            "Iter 6   time=0.41  loss=55945.70 active=52993 feature_norm=1.91\n",
            "Iter 7   time=0.15  loss=53396.17 active=53109 feature_norm=2.28\n",
            "Iter 8   time=0.29  loss=51539.35 active=52364 feature_norm=2.48\n",
            "Iter 9   time=0.14  loss=50137.26 active=52376 feature_norm=3.02\n",
            "Iter 10  time=0.15  loss=48922.18 active=52268 feature_norm=3.36\n",
            "Iter 11  time=0.14  loss=47648.92 active=60178 feature_norm=3.57\n",
            "Iter 12  time=0.14  loss=47323.16 active=60236 feature_norm=3.79\n",
            "Iter 13  time=0.14  loss=46900.09 active=60430 feature_norm=4.08\n",
            "Iter 14  time=0.14  loss=46560.70 active=60360 feature_norm=4.34\n",
            "Iter 15  time=0.14  loss=46078.09 active=60526 feature_norm=4.63\n",
            "Iter 16  time=0.14  loss=45633.03 active=60422 feature_norm=5.01\n",
            "Iter 17  time=0.14  loss=44927.75 active=60446 feature_norm=5.66\n",
            "Iter 18  time=0.15  loss=44163.04 active=60257 feature_norm=6.44\n",
            "Iter 19  time=0.15  loss=42683.13 active=60384 feature_norm=7.01\n",
            "Iter 20  time=0.15  loss=40019.85 active=60205 feature_norm=7.83\n",
            "Iter 21  time=0.28  loss=36188.59 active=59649 feature_norm=10.15\n",
            "Iter 22  time=0.14  loss=33836.13 active=59927 feature_norm=11.05\n",
            "Iter 23  time=0.14  loss=31862.36 active=59679 feature_norm=12.78\n",
            "Iter 24  time=0.14  loss=30244.01 active=59135 feature_norm=14.36\n",
            "Iter 25  time=0.14  loss=28811.37 active=57510 feature_norm=16.56\n",
            "Iter 26  time=0.14  loss=27295.50 active=53085 feature_norm=18.91\n",
            "Iter 27  time=0.14  loss=25833.02 active=51689 feature_norm=20.91\n",
            "Iter 28  time=0.14  loss=24484.54 active=50261 feature_norm=23.18\n",
            "Iter 29  time=0.14  loss=22504.58 active=46243 feature_norm=29.23\n",
            "Iter 30  time=0.14  loss=22300.21 active=43104 feature_norm=35.74\n",
            "Iter 31  time=0.14  loss=20542.90 active=43117 feature_norm=37.48\n",
            "Iter 32  time=0.14  loss=20002.72 active=42339 feature_norm=38.51\n",
            "Iter 33  time=0.14  loss=19503.68 active=42033 feature_norm=40.50\n",
            "Iter 34  time=0.14  loss=18613.16 active=40936 feature_norm=44.59\n",
            "Iter 35  time=0.14  loss=17706.84 active=39961 feature_norm=51.43\n",
            "Iter 36  time=0.14  loss=16939.00 active=39171 feature_norm=54.87\n",
            "Iter 37  time=0.14  loss=16340.12 active=38389 feature_norm=58.50\n",
            "Iter 38  time=0.14  loss=15220.35 active=37321 feature_norm=67.45\n",
            "Iter 39  time=0.14  loss=14640.31 active=36943 feature_norm=72.26\n",
            "Iter 40  time=0.14  loss=13977.97 active=36308 feature_norm=77.12\n",
            "Iter 41  time=0.14  loss=13130.92 active=35614 feature_norm=86.06\n",
            "Iter 42  time=0.14  loss=13042.85 active=35209 feature_norm=94.95\n",
            "Iter 43  time=0.14  loss=12348.90 active=35708 feature_norm=96.90\n",
            "Iter 44  time=0.14  loss=12157.64 active=35463 feature_norm=98.72\n",
            "Iter 45  time=0.14  loss=11931.94 active=32110 feature_norm=116.00\n",
            "Iter 46  time=0.14  loss=11214.73 active=32546 feature_norm=116.93\n",
            "Iter 47  time=0.14  loss=11114.87 active=32695 feature_norm=117.34\n",
            "Iter 48  time=0.14  loss=11027.42 active=32695 feature_norm=118.01\n",
            "Iter 49  time=0.14  loss=10897.49 active=32591 feature_norm=119.05\n",
            "Iter 50  time=0.14  loss=10406.77 active=31159 feature_norm=127.38\n",
            "Iter 51  time=0.28  loss=10357.44 active=31277 feature_norm=123.62\n",
            "Iter 52  time=0.14  loss=10277.30 active=31367 feature_norm=124.15\n",
            "Iter 53  time=0.15  loss=10210.76 active=31131 feature_norm=124.65\n",
            "Iter 54  time=0.14  loss=10102.40 active=30892 feature_norm=125.71\n",
            "Iter 55  time=0.14  loss=9941.23  active=30237 feature_norm=128.02\n",
            "Iter 56  time=0.28  loss=9926.91  active=29436 feature_norm=135.54\n",
            "Iter 57  time=0.14  loss=9766.31  active=29482 feature_norm=134.97\n",
            "Iter 58  time=0.14  loss=9709.81  active=29239 feature_norm=136.58\n",
            "Iter 59  time=0.14  loss=9566.34  active=27856 feature_norm=142.24\n",
            "Iter 60  time=0.14  loss=9525.19  active=27684 feature_norm=144.61\n",
            "Iter 61  time=0.14  loss=9479.81  active=27782 feature_norm=143.87\n",
            "Iter 62  time=0.14  loss=9448.92  active=27673 feature_norm=143.78\n",
            "Iter 63  time=0.14  loss=9394.48  active=27433 feature_norm=144.29\n",
            "Iter 64  time=0.14  loss=9358.19  active=27112 feature_norm=143.87\n",
            "Iter 65  time=0.14  loss=9299.11  active=26969 feature_norm=144.47\n",
            "Iter 66  time=0.14  loss=9266.76  active=26845 feature_norm=144.37\n",
            "Iter 67  time=0.14  loss=9169.71  active=26180 feature_norm=143.86\n",
            "Iter 68  time=0.28  loss=9157.14  active=26216 feature_norm=143.64\n",
            "Iter 69  time=0.14  loss=9127.28  active=26129 feature_norm=143.47\n",
            "Iter 70  time=0.14  loss=9083.95  active=25792 feature_norm=143.43\n",
            "Iter 71  time=0.14  loss=9045.45  active=25586 feature_norm=143.84\n",
            "Iter 72  time=0.14  loss=9005.02  active=25548 feature_norm=143.83\n",
            "Iter 73  time=0.14  loss=8966.85  active=25287 feature_norm=144.51\n",
            "Iter 74  time=0.14  loss=8932.21  active=25190 feature_norm=144.55\n",
            "Iter 75  time=0.14  loss=8900.04  active=25035 feature_norm=144.99\n",
            "Iter 76  time=0.14  loss=8866.33  active=24896 feature_norm=145.05\n",
            "Iter 77  time=0.14  loss=8835.95  active=24722 feature_norm=145.44\n",
            "Iter 78  time=0.14  loss=8810.34  active=24601 feature_norm=145.45\n",
            "Iter 79  time=0.14  loss=8788.70  active=24456 feature_norm=145.74\n",
            "Iter 80  time=0.14  loss=8769.10  active=24333 feature_norm=145.68\n",
            "Iter 81  time=0.14  loss=8749.75  active=24207 feature_norm=145.92\n",
            "Iter 82  time=0.14  loss=8732.80  active=24115 feature_norm=145.84\n",
            "Iter 83  time=0.14  loss=8716.82  active=23970 feature_norm=146.09\n",
            "Iter 84  time=0.14  loss=8701.83  active=23888 feature_norm=146.00\n",
            "Iter 85  time=0.14  loss=8688.53  active=23794 feature_norm=146.22\n",
            "Iter 86  time=0.14  loss=8675.96  active=23787 feature_norm=146.11\n",
            "Iter 87  time=0.14  loss=8664.95  active=23685 feature_norm=146.30\n",
            "Iter 88  time=0.14  loss=8654.58  active=23636 feature_norm=146.23\n",
            "Iter 89  time=0.14  loss=8645.24  active=23573 feature_norm=146.35\n",
            "Iter 90  time=0.14  loss=8636.31  active=23514 feature_norm=146.24\n",
            "Iter 91  time=0.15  loss=8628.90  active=23466 feature_norm=146.39\n",
            "Iter 92  time=0.14  loss=8621.25  active=23440 feature_norm=146.30\n",
            "Iter 93  time=0.15  loss=8613.81  active=23397 feature_norm=146.39\n",
            "Iter 94  time=0.14  loss=8606.02  active=23347 feature_norm=146.29\n",
            "Iter 95  time=0.15  loss=8600.99  active=23316 feature_norm=146.42\n",
            "Iter 96  time=0.14  loss=8594.63  active=23297 feature_norm=146.30\n",
            "Iter 97  time=0.14  loss=8589.79  active=23265 feature_norm=146.40\n",
            "Iter 98  time=0.14  loss=8584.32  active=23248 feature_norm=146.33\n",
            "Iter 99  time=0.14  loss=8578.63  active=23202 feature_norm=146.40\n",
            "Iter 100 time=0.14  loss=8574.22  active=23162 feature_norm=146.28\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 15.422\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 23162 (61278)\n",
            "Number of active attributes: 13776 (49559)\n",
            "Number of active labels: 15 (15)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.012\n",
            "\n",
            "Entraînement terminé en 16.66 secondes\n"
          ]
        }
      ],
      "source": [
        "    crf, training_time = train_crf_model(X_train, y_train)\n",
        "\n",
        "    import pickle\n",
        "\n",
        "    with open('/content/drive/MyDrive/modele_CRF_NER.pkl', 'wb') as f:\n",
        "        pickle.dump(crf, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Po-qOyiuXf6q",
        "outputId": "b1f321e1-0b4a-4bbf-ecec-35d5005acd38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Évaluation du modèle...\n",
            "Temps d'inférence: 0.5130 secondes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Classification Report ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "         B-LOC       0.76      0.54      0.63      1591\n",
            "   B-LOCI-PERS       0.00      0.00      0.00         1\n",
            "        B-MISC       0.72      0.31      0.43       413\n",
            "         B-OEG       0.00      0.00      0.00         1\n",
            "         B-ORG       0.73      0.43      0.54       712\n",
            "        B-PERS       0.70      0.47      0.57      1289\n",
            "        B-PERs       0.00      0.00      0.00         1\n",
            "         B-PRG       0.00      0.00      0.00         1\n",
            "         I-LOC       0.81      0.49      0.61       261\n",
            "        I-MISC       0.68      0.24      0.35       174\n",
            "         I-ORG       0.76      0.53      0.62       446\n",
            "        I-PERS       0.78      0.60      0.68      1045\n",
            "         IPERS       0.00      0.00      0.00         1\n",
            "             O       0.95      0.99      0.97     50319\n",
            "      Oالإصابة       0.00      0.00      0.00         1\n",
            "        b-misc       0.00      0.00      0.00         1\n",
            "        i-misc       0.00      0.00      0.00         1\n",
            "             o       0.00      0.00      0.00         2\n",
            "ونايفة</title>       0.00      0.00      0.00         1\n",
            "             ‏       0.00      0.00      0.00         1\n",
            "\n",
            "      accuracy                           0.94     56262\n",
            "     macro avg       0.35      0.23      0.27     56262\n",
            "  weighted avg       0.93      0.94      0.93     56262\n",
            "\n",
            "\n",
            "--- Summary Metrics ---\n",
            "Accuracy: 0.9373\n",
            "Precision (micro): 0.7486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def evaluate_model(crf, X_test, y_test):\n",
        "    print(\"Évaluation du modèle...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    y_pred = crf.predict(X_test)\n",
        "    inference_time = time.time() - start_time\n",
        "    print(f\"Temps d'inférence: {inference_time:.4f} secondes\")\n",
        "\n",
        "    \n",
        "    labels = sorted(set([tag for seq in y_test for tag in seq if tag != 'O']))\n",
        "\n",
        "    results = {\n",
        "        'accuracy': metrics.flat_accuracy_score(y_test, y_pred),\n",
        "        'precision_micro': metrics.flat_precision_score(y_test, y_pred, average='micro', labels=labels),\n",
        "\n",
        "        'classification_report': classification_report([tag for seq in y_test for tag in seq],\n",
        "                                                     [tag for seq in y_pred for tag in seq]),\n",
        "        'inference_time': inference_time\n",
        "    }\n",
        "\n",
        "    print(\"--- Classification Report ---\")\n",
        "    print(results['classification_report'])\n",
        "\n",
        "    print(\"\\n--- Summary Metrics ---\")\n",
        "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
        "    print(f\"Precision (micro): {results['precision_micro']:.4f}\")\n",
        "\n",
        "    return results, y_pred\n",
        "results, y_pred= evaluate_model(crf, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBHwh8W6e1Wt",
        "outputId": "84d13f4f-36ab-4aa6-efef-47d0bbf2c3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Résultats de la reconnaissance d'entités nommées ===\n",
            "Phrase: زار محمد علي مكاتب شركة جوجل في القاهرة أمس\n",
            "\n",
            "Entités identifiées:\n",
            "  PERS:\n",
            "    - محمد\n",
            "  ORG:\n",
            "    - جوجل\n",
            "\n",
            "Phrase étiquetée:\n",
            "زار -> O\n",
            "محمد -> B-PERS\n",
            "علي -> O\n",
            "مكاتب -> O\n",
            "شركة -> O\n",
            "جوجل -> B-ORG\n",
            "في -> O\n",
            "القاهرة -> O\n",
            "أمس -> O\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "def prepare_sentence_features(sentence):\n",
        "    words = sentence.split()\n",
        "    X_sent = []\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        X_sent.append(extract_features(words, i))\n",
        "\n",
        "    return X_sent\n",
        "\n",
        "def predict_entities(model_path, sentence):\n",
        "    crf = joblib.load(model_path)\n",
        "\n",
        "    words = sentence.split()\n",
        "\n",
        "    X_sent = prepare_sentence_features(sentence)\n",
        "\n",
        "    y_pred = crf.predict([X_sent])[0]\n",
        "\n",
        "    tagged_sentence = list(zip(words, y_pred))\n",
        "\n",
        "    return tagged_sentence\n",
        "\n",
        "def extract_named_entities(tagged_sentence):\n",
        "    entities = {}\n",
        "    current_entity = []\n",
        "    current_tag = None\n",
        "\n",
        "    for word, tag in tagged_sentence:\n",
        "        if tag.startswith('B-'):\n",
        "            if current_entity:\n",
        "                entity_text = ' '.join(current_entity)\n",
        "                entity_type = current_tag[2:]\n",
        "\n",
        "                if entity_type not in entities:\n",
        "                    entities[entity_type] = []\n",
        "                entities[entity_type].append(entity_text)\n",
        "\n",
        "                current_entity = []\n",
        "\n",
        "            current_entity.append(word)\n",
        "            current_tag = tag\n",
        "\n",
        "        elif tag.startswith('I-') and current_entity and tag[2:] == current_tag[2:]:\n",
        "            current_entity.append(word)\n",
        "\n",
        "        else:  \n",
        "            if current_entity:\n",
        "                entity_text = ' '.join(current_entity)\n",
        "                entity_type = current_tag[2:] \n",
        "\n",
        "                if entity_type not in entities:\n",
        "                    entities[entity_type] = []\n",
        "                entities[entity_type].append(entity_text)\n",
        "\n",
        "                current_entity = []\n",
        "                current_tag = None\n",
        "\n",
        "            if tag.startswith('B-'):  \n",
        "                current_entity.append(word)\n",
        "                current_tag = tag\n",
        "\n",
        "    if current_entity:\n",
        "        entity_text = ' '.join(current_entity)\n",
        "        entity_type = current_tag[2:] \n",
        "\n",
        "        if entity_type not in entities:\n",
        "            entities[entity_type] = []\n",
        "        entities[entity_type].append(entity_text)\n",
        "\n",
        "    return entities\n",
        "\n",
        "def test_model_on_sentence(model_path, sentence):\n",
        "    tagged_sentence = predict_entities(model_path, sentence)\n",
        "\n",
        "    entities = extract_named_entities(tagged_sentence)\n",
        "\n",
        "    print(\"=== Résultats de la reconnaissance d'entités nommées ===\")\n",
        "    print(f\"Phrase: {sentence}\")\n",
        "    print(\"\\nEntités identifiées:\")\n",
        "\n",
        "    for entity_type, entity_list in entities.items():\n",
        "        print(f\"  {entity_type}:\")\n",
        "        for entity in entity_list:\n",
        "            print(f\"    - {entity}\")\n",
        "\n",
        "    print(\"\\nPhrase étiquetée:\")\n",
        "    for word, tag in tagged_sentence:\n",
        "        print(f\"{word} -> {tag}\")\n",
        "\n",
        "    return entities, tagged_sentence\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/modele_CRF_NER.pkl\"\n",
        "\n",
        "sentence =\"زار محمد علي مكاتب شركة جوجل في القاهرة أمس\"\n",
        "\n",
        "entities, tagged_sentence = test_model_on_sentence(model_path, sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV9l1dMYaayc"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 100\n",
        "EMBEDDING_DIM = 32\n",
        "LSTM_UNITS = 100          \n",
        "BATCH_SIZE = 10\n",
        "EPOCHS = 1\n",
        "def preprocess_data(df):\n",
        "    df = df.dropna(subset=['text', 'label'])\n",
        "\n",
        "    texts = df['text'].tolist()\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    texts_tokenized = [str(text).split() for text in texts]\n",
        "    labels_tokenized = [str(label).split() for label in labels]\n",
        "\n",
        "    words = set([word for text in texts_tokenized for word in text])\n",
        "    labels_set = set([label for label_seq in labels_tokenized for label in label_seq])\n",
        "\n",
        "    word_to_idx = {word: idx + 1 for idx, word in enumerate(words)} \n",
        "    label_to_idx = {label: idx for idx, label in enumerate(labels_set)}\n",
        "\n",
        "    X = [[word_to_idx.get(word, 0) for word in text] for text in texts_tokenized]\n",
        "    y = [[label_to_idx.get(label, 0) for label in label_seq] for label_seq in labels_tokenized]\n",
        "\n",
        "    X_padded = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post', dtype='int32')\n",
        "    y_padded = pad_sequences(y, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post', dtype='int32')\n",
        "\n",
        "\n",
        "    num_labels = len(label_to_idx)\n",
        "    y_one_hot = np.array([to_categorical(label_seq, num_classes=num_labels) for label_seq in y_padded], dtype='float16')\n",
        "\n",
        "    return X_padded, y_one_hot, word_to_idx, label_to_idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npcSHm3Raarj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "def create_bilstm_crf_model(vocab_size, num_labels):\n",
        "    input_layer = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "    model = Embedding(input_dim=len(word_to_idx) + 1, output_dim=32, input_length=MAX_SEQUENCE_LENGTH, mask_zero=True)(input_layer)\n",
        "    model = Bidirectional(LSTM(units=64, return_sequences=True,dropout=0.4, recurrent_dropout=0.2))(model)\n",
        "\n",
        "    output = TimeDistributed(Dense(25, activation=\"softmax\"))(model)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=['accuracy',  Precision(), Recall()]\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrNdAgqraaLN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "def evaluate_model(model, X_test, y_test, idx_to_label):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_argmax = np.argmax(y_pred, axis=-1)\n",
        "    y_test_argmax = np.argmax(y_test, axis=-1)\n",
        "\n",
        "    y_pred_flat = []\n",
        "    y_test_flat = []\n",
        "\n",
        "    for i in range(len(y_test_argmax)):\n",
        "        for j in range(len(y_test_argmax[i])):\n",
        "           \n",
        "            if y_test_argmax[i][j] != 0:  \n",
        "                y_test_flat.append(idx_to_label[y_test_argmax[i][j]])\n",
        "                y_pred_flat.append(idx_to_label[y_pred_argmax[i][j]])\n",
        "\n",
        "    report = classification_report(y_test_flat, y_pred_flat, zero_division=0)\n",
        "    f1 = f1_score(y_test_flat, y_pred_flat, average='weighted', zero_division=0)\n",
        "    acc= accuracy_score(y_test_flat,y_pred_flat)\n",
        "\n",
        "    return report, f1, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgpcJUMDartA"
      },
      "outputs": [],
      "source": [
        "X, y, word_to_idx, label_to_idx = preprocess_data(data)\n",
        "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "X_test = tf.convert_to_tensor(X_test)\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "y_test = tf.convert_to_tensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1fG6GVtBci6",
        "outputId": "b53b99b3-be2c-46c6-8d9a-ff7f27689995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 32)           1062560   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 128)         49664     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 100, 25)          3225      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,115,449\n",
            "Trainable params: 1,115,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "10697/10697 [==============================] - 2857s 266ms/step - loss: 0.3765 - accuracy: 0.9141 - precision: 0.9417 - recall: 0.8912 - val_loss: 0.2531 - val_accuracy: 0.9379 - val_precision: 0.9552 - val_recall: 0.9265\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(word_to_idx)\n",
        "num_labels = len(label_to_idx)\n",
        "model = create_bilstm_crf_model(vocab_size, num_labels)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       epochs=EPOCHS,\n",
        "                       validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-aOOm5parni",
        "outputId": "e2c3954a-7342-43e1-b95f-72dd9f0ff2fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "929/929 [==============================] - 35s 37ms/step\n",
            "Rapport de classification :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-ERS       0.00      0.00      0.00         1\n",
            "       B-LOC       0.86      0.73      0.79       825\n",
            "      B-MISC       0.00      0.00      0.00         0\n",
            "       B-ORG       0.82      0.44      0.57       430\n",
            "      B-PERS       0.64      0.57      0.60       711\n",
            "       B-PRG       0.00      0.00      0.00         1\n",
            "       I-LOC       0.51      0.43      0.46       103\n",
            "      I-MISC       0.00      0.00      0.00       111\n",
            "       I-ORG       0.65      0.08      0.15       267\n",
            "      I-PERS       0.57      0.16      0.24       546\n",
            "       I-PRG       0.00      0.00      0.00         1\n",
            "           O       0.95      1.00      0.98     26482\n",
            "    Oالإصابة       0.00      0.00      0.00         1\n",
            "      i-misc       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.94     29480\n",
            "   macro avg       0.36      0.24      0.27     29480\n",
            "weighted avg       0.93      0.94      0.93     29480\n",
            "\n",
            "Score F1 : 0.9283645220423089\n",
            "Accuracy : 0.9407394843962008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "report, f1 , acc= evaluate_model(model, X_test, y_test, idx_to_label)\n",
        "print(\"Rapport de classification :\")\n",
        "print(report)\n",
        "print(f\"Score F1 : {f1}\")\n",
        "print(f\"Accuracy : {acc}\")\n",
        "\n",
        "model.save(\"/content/drive/MyDrive/modele_BILSTM_NER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WFWu27YvBeGG"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/word_to_idx.pkl', 'wb') as f:\n",
        "    pickle.dump(word_to_idx, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/idx_to_label.pkl', 'wb') as f:\n",
        "    pickle.dump(idx_to_label, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN6Sc_DGqDf1",
        "outputId": "32cdf746-5efe-4ef2-d5af-9a0f416f6e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 538ms/step\n",
            "Étiquettes prédites: ['O', 'B-PERS', 'O', 'B-LOC']\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def predict_for_new_text(new_text, model_path, word_to_idx, label_to_idx, max_seq_length=100):\n",
        "    loaded_model = load_model(model_path)\n",
        "\n",
        "    tokens = str(new_text).split()\n",
        "\n",
        "    sequence = [word_to_idx.get(word, 0) for word in tokens] \n",
        "\n",
        "    padded_sequence = pad_sequences([sequence], maxlen=max_seq_length, padding='post', truncating='post', dtype='int32')\n",
        "\n",
        "    predictions = loaded_model.predict(padded_sequence)\n",
        "\n",
        "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
        "    predicted_indices = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    result = []\n",
        "    for i, idx in enumerate(predicted_indices[0]):\n",
        "        if i >= len(tokens):  \n",
        "            break\n",
        "        result.append(idx_to_label[idx])\n",
        "\n",
        "    return result\n",
        "\n",
        "     new_phrase =\"ذهب أحمد إلى القاهرة\"\n",
        "model_path = \"/content/drive/MyDrive/modele_BILSTM_NER\"\n",
        "prediction = predict_for_new_text(new_phrase, model_path, word_to_idx, label_to_idx)\n",
        "print(f\"Étiquettes prédites: {prediction}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
