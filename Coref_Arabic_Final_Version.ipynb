{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6691038a60e54abfab9445bdad0fa41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb00efc440ad4e7f8ad8fdc18a7913bf",
              "IPY_MODEL_f47bef834f064a5ca883e975ae554cc6",
              "IPY_MODEL_70006a30c2db4c5ba899db3aa2914d92"
            ],
            "layout": "IPY_MODEL_60ea5bcc1cbc4d59bdd7e633f9473ad9"
          }
        },
        "eb00efc440ad4e7f8ad8fdc18a7913bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7ec90540d9649859ba5e486c1ae8599",
            "placeholder": "​",
            "style": "IPY_MODEL_a6ca97441b9a4da4b5c1212f90edf120",
            "value": "Traitement des documents: 100%"
          }
        },
        "f47bef834f064a5ca883e975ae554cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4f879e0a6034b178c876f75ba92df34",
            "max": 447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f93f830ea1504d81adcbd841dfdea6bc",
            "value": 447
          }
        },
        "70006a30c2db4c5ba899db3aa2914d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71620799bf14380ad3e451b3a26aa5b",
            "placeholder": "​",
            "style": "IPY_MODEL_ae9e0ad2ab2c40288171d6f504d912f4",
            "value": " 447/447 [01:19&lt;00:00,  3.44it/s]"
          }
        },
        "60ea5bcc1cbc4d59bdd7e633f9473ad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ec90540d9649859ba5e486c1ae8599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ca97441b9a4da4b5c1212f90edf120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4f879e0a6034b178c876f75ba92df34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f93f830ea1504d81adcbd841dfdea6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c71620799bf14380ad3e451b3a26aa5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae9e0ad2ab2c40288171d6f504d912f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xZcr3xO3iyAf",
        "outputId": "f51016c2-aff4-4837-b237-5fa0ac8b1226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scipy 1.15.3\n",
            "Uninstalling scipy-1.15.3:\n",
            "  Successfully uninstalled scipy-1.15.3\n",
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-addons as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cvxpy 1.6.5 requires scipy>=1.11.0, which is not installed.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\n",
            "jax 0.5.2 requires scipy>=1.11.1, which is not installed.\n",
            "mizani 0.13.5 requires scipy>=1.8.0, which is not installed.\n",
            "cuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\n",
            "mlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\n",
            "arviz 0.21.0 requires scipy>=1.9.0, which is not installed.\n",
            "lightgbm 4.5.0 requires scipy, which is not installed.\n",
            "stumpy 1.13.0 requires scipy>=1.10, which is not installed.\n",
            "scs 3.2.7.post2 requires scipy, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "umap-learn 0.5.7 requires scipy>=1.3.1, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\n",
            "xgboost 2.1.4 requires scipy, which is not installed.\n",
            "shap 0.47.2 requires scipy, which is not installed.\n",
            "fastai 2.7.19 requires scipy, which is not installed.\n",
            "pytensor 2.30.3 requires scipy<2,>=1, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\n",
            "matplotlib-venn 1.1.2 requires scipy, which is not installed.\n",
            "hyperopt 0.2.7 requires scipy, which is not installed.\n",
            "pymc 5.22.0 requires scipy>=1.4.1, which is not installed.\n",
            "clarabel 0.10.0 requires scipy, which is not installed.\n",
            "hdbscan 0.8.40 requires scipy>=1.0, which is not installed.\n",
            "yellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\n",
            "treelite 4.4.1 requires scipy, which is not installed.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "libpysal 4.13.0 requires scipy>=1.8, which is not installed.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "albumentations 2.0.6 requires scipy>=1.10.0, which is not installed.\n",
            "plotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\n",
            "datascience 0.17.6 requires scipy, which is not installed.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "scikit-learn 1.6.1 requires scipy>=1.6.0, which is not installed.\n",
            "osqp 1.0.4 requires scipy>=0.13.2, which is not installed.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, which is not installed.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.4.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2b9bd126cf934acf82a1a403ef563bb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scipy==1.10.1) (1.23.5)\n",
            "Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "cvxpy 1.6.5 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.10.1\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m834.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, keras, gast, jaxlib, jax, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 protobuf-4.25.7 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "jax",
                  "jaxlib",
                  "keras",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "0df5ae2c92db42a7880a8f57f2412ef2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.20.0\n",
            "  Downloading tensorflow_addons-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons==0.20.0) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==0.20.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y scipy numpy tensorflow tensorflow-addons\n",
        "!pip install numpy==1.23.5\n",
        "!pip install scipy==1.10.1\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install tensorflow-addons==0.20.0\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, Embedding, Flatten, LSTM, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "gjiFmcfNnL9_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzgc5YvJoXGd",
        "outputId": "b3586363-dbfb-4727-bd19-e41ca3e8ec18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_coref_data(coref_file_path):\n",
        "    with open(coref_file_path, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    text_match = re.search(r'<TEXT[^>]*>(.*?)</TEXT>', content, re.DOTALL)\n",
        "    if not text_match:\n",
        "        return None, {}\n",
        "\n",
        "    text = text_match.group(1)\n",
        "\n",
        "    coref_chains = defaultdict(list)\n",
        "    coref_tags = re.finditer(r'<COREF ID=\"(\\d+)\" TYPE=\"([^\"]+)\"[^>]*>(.*?)</COREF>', text, re.DOTALL)\n",
        "\n",
        "    for match in coref_tags:\n",
        "        coref_id = match.group(1)\n",
        "        coref_type = match.group(2)\n",
        "        mention_text = match.group(3)\n",
        "\n",
        "        clean_text = re.sub(r'<[^>]+>', '', mention_text)\n",
        "\n",
        "        coref_chains[coref_id].append({\n",
        "            'text': clean_text,\n",
        "            'type': coref_type,\n",
        "            'start': match.start(),\n",
        "            'end': match.end()\n",
        "        })\n",
        "\n",
        "    return text, dict(coref_chains)"
      ],
      "metadata": {
        "id": "Bbjd6GiVnL6g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_onf_data(onf_file_path):\n",
        "    with open(onf_file_path, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    plain_sentences = []\n",
        "    plain_matches = re.finditer(r'Plain sentence:\\n---------------\\n(.*?)Treebanked sentence:', content, re.DOTALL)\n",
        "    for match in plain_matches:\n",
        "        plain_sentences.append(match.group(1).strip())\n",
        "\n",
        "    treebanked_sentences = []\n",
        "    tree_matches = re.finditer(r'Treebanked sentence:\\n--------------------\\n(.*?)Tree:', content, re.DOTALL)\n",
        "    for match in tree_matches:\n",
        "        treebanked_sentences.append(match.group(1).strip())\n",
        "\n",
        "    all_tokens = []\n",
        "    leaves_sections = re.finditer(r'Leaves:\\n-------\\n(.*?)(?=---------|$)', content, re.DOTALL)\n",
        "\n",
        "    sentence_idx = 0\n",
        "    for leaves_section in leaves_sections:\n",
        "        leaves_text = leaves_section.group(1)\n",
        "\n",
        "        token_matches = re.finditer(r'(\\d+)\\s+(\\S+)\\s+(.*?)(?=\\n\\s+\\d+|\\n\\S|$)', leaves_text, re.DOTALL)\n",
        "\n",
        "        for match in token_matches:\n",
        "            token_id = int(match.group(1))\n",
        "            token = match.group(2)\n",
        "            token_metadata = match.group(3).strip()\n",
        "\n",
        "            coref_match = re.search(r'coref:\\s+IDENT\\s+(\\d+)', token_metadata)\n",
        "            coref_id = coref_match.group(1) if coref_match else None\n",
        "\n",
        "            named_entity_match = re.search(r'name:\\s+(\\S+)', token_metadata)\n",
        "            named_entity = named_entity_match.group(1) if named_entity_match else None\n",
        "\n",
        "            sense_match = re.search(r'sense:\\s+(\\S+)', token_metadata)\n",
        "            sense = sense_match.group(1) if sense_match else None\n",
        "\n",
        "            current_sentence = \"\"\n",
        "            if sentence_idx < len(plain_sentences):\n",
        "                current_sentence = plain_sentences[sentence_idx]\n",
        "\n",
        "            all_tokens.append({\n",
        "                'token_id': token_id,\n",
        "                'token': token,\n",
        "                'sentence_idx': sentence_idx,\n",
        "                'sentence': current_sentence,\n",
        "                'coref_id': coref_id,\n",
        "                'named_entity': named_entity,\n",
        "                'sense': sense,\n",
        "                'metadata': token_metadata\n",
        "            })\n",
        "\n",
        "        sentence_idx += 1\n",
        "\n",
        "    return all_tokens"
      ],
      "metadata": {
        "id": "pyFeLWQZnL3l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(root_dir):\n",
        "    all_documents = []\n",
        "\n",
        "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.coref'):\n",
        "                doc_id = filename[:-6]\n",
        "                coref_path = os.path.join(dirpath, filename)\n",
        "                onf_path = os.path.join(dirpath, f\"{doc_id}.onf\")\n",
        "\n",
        "                if os.path.exists(onf_path):\n",
        "                    text, coref_chains = extract_coref_data(coref_path)\n",
        "                    tokens_info = extract_onf_data(onf_path)\n",
        "\n",
        "                    if text and tokens_info:\n",
        "                        all_documents.append({\n",
        "                            'doc_id': doc_id,\n",
        "                            'text': text,\n",
        "                            'coref_chains': coref_chains,\n",
        "                            'tokens': tokens_info\n",
        "                        })\n",
        "\n",
        "    return all_documents"
      ],
      "metadata": {
        "id": "4IE3aZegnLkG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_ontonotes_to_dataframes(root_dir):\n",
        "    documents_data = []\n",
        "    tokens_data = []\n",
        "    coref_mentions_data = []\n",
        "    coref_chains_data = []\n",
        "\n",
        "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.coref'):\n",
        "                doc_id = filename[:-6]\n",
        "                coref_path = os.path.join(dirpath, filename)\n",
        "                onf_path = os.path.join(dirpath, f\"{doc_id}.onf\")\n",
        "\n",
        "                if os.path.exists(onf_path):\n",
        "                    text, coref_chains = extract_coref_data(coref_path)\n",
        "\n",
        "                    tokens_info = extract_onf_data(onf_path)\n",
        "\n",
        "                    if text and tokens_info:\n",
        "                        doc_info = {\n",
        "                            'doc_id': doc_id,\n",
        "                            'path': dirpath,\n",
        "                            'num_tokens': len(tokens_info),\n",
        "                            'num_coref_chains': len(coref_chains),\n",
        "                        }\n",
        "                        documents_data.append(doc_info)\n",
        "\n",
        "                        for token in tokens_info:\n",
        "                            token_info = {\n",
        "                                'doc_id': doc_id,\n",
        "                                **token\n",
        "                            }\n",
        "                            tokens_data.append(token_info)\n",
        "\n",
        "                        for chain_id, mentions in coref_chains.items():\n",
        "                            for mention_idx, mention in enumerate(mentions):\n",
        "                                mention_info = {\n",
        "                                    'doc_id': doc_id,\n",
        "                                    'chain_id': chain_id,\n",
        "                                    'mention_idx': mention_idx,\n",
        "                                    'mention_text': mention['text'],\n",
        "                                    'mention_type': mention['type'],\n",
        "                                    'start_pos': mention['start'],\n",
        "                                    'end_pos': mention['end']\n",
        "                                }\n",
        "                                coref_mentions_data.append(mention_info)\n",
        "\n",
        "                            chain_info = {\n",
        "                                'doc_id': doc_id,\n",
        "                                'chain_id': chain_id,\n",
        "                                'num_mentions': len(mentions),\n",
        "                                'mentions_text': [m['text'] for m in mentions]\n",
        "                            }\n",
        "                            coref_chains_data.append(chain_info)\n",
        "\n",
        "    df_documents = pd.DataFrame(documents_data)\n",
        "    df_tokens = pd.DataFrame(tokens_data)\n",
        "    df_mentions = pd.DataFrame(coref_mentions_data)\n",
        "    df_chains = pd.DataFrame(coref_chains_data)\n",
        "\n",
        "    return df_documents, df_tokens, df_mentions, df_chains"
      ],
      "metadata": {
        "id": "VBDOavdWrvpi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/ann'\n",
        "output_dir = '/content/drive/MyDrive/ontonotes_dataframes'\n",
        "\n",
        "df_documents, df_tokens, df_mentions, df_chains = process_ontonotes_to_dataframes(data_dir)\n"
      ],
      "metadata": {
        "id": "zE9uAAE_ofSK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mentions.tail(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FGqjN5rXxgvh",
        "outputId": "68c743f3-a939-4d0b-cf58-55f6d37c7882"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         doc_id chain_id  mention_idx  \\\n",
              "35827  ann_0178    29590            0   \n",
              "35828  ann_0178    29599            0   \n",
              "35829  ann_0178    29599            1   \n",
              "35830  ann_0178    29614            0   \n",
              "35831  ann_0178    29614            1   \n",
              "\n",
              "                                       mention_text mention_type  start_pos  \\\n",
              "35827                                   كارول كالين        APPOS      17079   \n",
              "35828  -المُسْتَشارَةُ السِياسِيَّةُ فِي السِفارَةِ        APPOS      17232   \n",
              "35829                                      آن بودين        APPOS      17333   \n",
              "35830                                  المُحادَثاتِ        IDENT      18009   \n",
              "35831                                           -ها        IDENT      18083   \n",
              "\n",
              "       end_pos  \n",
              "35827    17144  \n",
              "35828    17332  \n",
              "35829    17395  \n",
              "35830    18060  \n",
              "35831    18135  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e653d67-281b-4d2a-8868-b3039450f242\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>chain_id</th>\n",
              "      <th>mention_idx</th>\n",
              "      <th>mention_text</th>\n",
              "      <th>mention_type</th>\n",
              "      <th>start_pos</th>\n",
              "      <th>end_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35827</th>\n",
              "      <td>ann_0178</td>\n",
              "      <td>29590</td>\n",
              "      <td>0</td>\n",
              "      <td>كارول كالين</td>\n",
              "      <td>APPOS</td>\n",
              "      <td>17079</td>\n",
              "      <td>17144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35828</th>\n",
              "      <td>ann_0178</td>\n",
              "      <td>29599</td>\n",
              "      <td>0</td>\n",
              "      <td>-المُسْتَشارَةُ السِياسِيَّةُ فِي السِفارَةِ</td>\n",
              "      <td>APPOS</td>\n",
              "      <td>17232</td>\n",
              "      <td>17332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35829</th>\n",
              "      <td>ann_0178</td>\n",
              "      <td>29599</td>\n",
              "      <td>1</td>\n",
              "      <td>آن بودين</td>\n",
              "      <td>APPOS</td>\n",
              "      <td>17333</td>\n",
              "      <td>17395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35830</th>\n",
              "      <td>ann_0178</td>\n",
              "      <td>29614</td>\n",
              "      <td>0</td>\n",
              "      <td>المُحادَثاتِ</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>18009</td>\n",
              "      <td>18060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35831</th>\n",
              "      <td>ann_0178</td>\n",
              "      <td>29614</td>\n",
              "      <td>1</td>\n",
              "      <td>-ها</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>18083</td>\n",
              "      <td>18135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e653d67-281b-4d2a-8868-b3039450f242')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e653d67-281b-4d2a-8868-b3039450f242 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e653d67-281b-4d2a-8868-b3039450f242');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9e80d3b5-3d8c-4b9f-b044-7db9537864d9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e80d3b5-3d8c-4b9f-b044-7db9537864d9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9e80d3b5-3d8c-4b9f-b044-7db9537864d9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_mentions\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"doc_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ann_0178\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chain_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"29590\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mention_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mention_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"-\\u0627\\u0644\\u0645\\u064f\\u0633\\u0652\\u062a\\u064e\\u0634\\u0627\\u0631\\u064e\\u0629\\u064f \\u0627\\u0644\\u0633\\u0650\\u064a\\u0627\\u0633\\u0650\\u064a\\u0651\\u064e\\u0629\\u064f \\u0641\\u0650\\u064a \\u0627\\u0644\\u0633\\u0650\\u0641\\u0627\\u0631\\u064e\\u0629\\u0650\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mention_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"IDENT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_pos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 464,\n        \"min\": 17079,\n        \"max\": 18083,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          17232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_pos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 452,\n        \"min\": 17144,\n        \"max\": 18135,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          17332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_tashkeel(w):\n",
        "    p_tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
        "    w = re.sub(p_tashkeel, \"\", w)\n",
        "    return w"
      ],
      "metadata": {
        "id": "2KwKEJSpHnjl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(df_mentions, df_tokens, max_distance=50, max_pairs_per_doc=10000):\n",
        "    feature_data = []\n",
        "\n",
        "    for doc_id in tqdm(df_mentions['doc_id'].unique(), desc=\"Traitement des documents\"):\n",
        "        doc_mentions = df_mentions[df_mentions['doc_id'] == doc_id].sort_values('start_pos').reset_index(drop=True)\n",
        "        doc_tokens = df_tokens[df_tokens['doc_id'] == doc_id]\n",
        "\n",
        "        pairs_count = 0\n",
        "\n",
        "        for i, mention1 in doc_mentions.iterrows():\n",
        "            if pairs_count >= max_pairs_per_doc:\n",
        "                break\n",
        "\n",
        "            for j, mention2 in doc_mentions.iloc[i+1:].iterrows():\n",
        "                if mention2['start_pos'] - mention1['end_pos'] > max_distance:\n",
        "                    continue\n",
        "\n",
        "                is_coreferent = int(mention1['chain_id'] == mention2['chain_id'] and mention1['chain_id'] is not None)\n",
        "\n",
        "                m1_text = remove_tashkeel(mention1['mention_text'])\n",
        "                m2_text = remove_tashkeel(mention2['mention_text'])\n",
        "\n",
        "                token_distance = mention2['start_pos'] - mention1['end_pos']\n",
        "\n",
        "                mention_types = {\n",
        "                    'm1_type': mention1['mention_type'],\n",
        "                    'm2_type': mention2['mention_type']\n",
        "                }\n",
        "\n",
        "                feature_data.append({\n",
        "                    'doc_id': doc_id,\n",
        "                    'mention1_id': i,\n",
        "                    'mention2_id': j,\n",
        "                    'm1_text': m1_text,\n",
        "                    'm2_text': m2_text,\n",
        "                    'token_distance': token_distance,\n",
        "                    'm1_type': mention_types['m1_type'],\n",
        "                    'm2_type': mention_types['m2_type'],\n",
        "                    'is_coreferent': is_coreferent\n",
        "                })\n",
        "\n",
        "                pairs_count += 1\n",
        "\n",
        "    df_pairs = pd.DataFrame(feature_data)\n",
        "\n",
        "    return df_pairs\n"
      ],
      "metadata": {
        "id": "e2dGuzuNCu74"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pairs= prepare_dataset(df_mentions,df_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6691038a60e54abfab9445bdad0fa41b",
            "eb00efc440ad4e7f8ad8fdc18a7913bf",
            "f47bef834f064a5ca883e975ae554cc6",
            "70006a30c2db4c5ba899db3aa2914d92",
            "60ea5bcc1cbc4d59bdd7e633f9473ad9",
            "c7ec90540d9649859ba5e486c1ae8599",
            "a6ca97441b9a4da4b5c1212f90edf120",
            "d4f879e0a6034b178c876f75ba92df34",
            "f93f830ea1504d81adcbd841dfdea6bc",
            "c71620799bf14380ad3e451b3a26aa5b",
            "ae9e0ad2ab2c40288171d6f504d912f4"
          ]
        },
        "id": "qZQN7NaPEvh7",
        "outputId": "176624cb-b025-44c3-9972-83f438851939"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Traitement des documents:   0%|          | 0/447 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6691038a60e54abfab9445bdad0fa41b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pairs.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ehu5HU94FEmL",
        "outputId": "37ce8d0d-6ab4-40d2-fb1c-e2bf23fa77ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     doc_id  mention1_id  mention2_id           m1_text       m2_text  \\\n",
              "0  ann_0205            0            1  الكؤوس الإفريقية       الزمالك   \n",
              "1  ann_0205            1            2           الزمالك       -الأهلي   \n",
              "2  ann_0205            2            3           -الأهلي       -الترجي   \n",
              "3  ann_0205            3            4           -الترجي       -الرجاء   \n",
              "4  ann_0205            4            5           -الرجاء  دوري الأبطال   \n",
              "\n",
              "   token_distance m1_type m2_type  is_coreferent  \n",
              "0               8   IDENT   IDENT              0  \n",
              "1               5   IDENT   IDENT              0  \n",
              "2               5   IDENT   IDENT              0  \n",
              "3               5   IDENT   IDENT              0  \n",
              "4               1   IDENT   IDENT              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49ce1af4-4e2d-4bb7-9fd2-04f543004f7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>mention1_id</th>\n",
              "      <th>mention2_id</th>\n",
              "      <th>m1_text</th>\n",
              "      <th>m2_text</th>\n",
              "      <th>token_distance</th>\n",
              "      <th>m1_type</th>\n",
              "      <th>m2_type</th>\n",
              "      <th>is_coreferent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ann_0205</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>الكؤوس الإفريقية</td>\n",
              "      <td>الزمالك</td>\n",
              "      <td>8</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ann_0205</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>الزمالك</td>\n",
              "      <td>-الأهلي</td>\n",
              "      <td>5</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ann_0205</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-الأهلي</td>\n",
              "      <td>-الترجي</td>\n",
              "      <td>5</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ann_0205</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>-الترجي</td>\n",
              "      <td>-الرجاء</td>\n",
              "      <td>5</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ann_0205</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>-الرجاء</td>\n",
              "      <td>دوري الأبطال</td>\n",
              "      <td>1</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>IDENT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49ce1af4-4e2d-4bb7-9fd2-04f543004f7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49ce1af4-4e2d-4bb7-9fd2-04f543004f7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49ce1af4-4e2d-4bb7-9fd2-04f543004f7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f4776a21-6f2d-4f6d-ac32-6488bd111b7a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4776a21-6f2d-4f6d-ac32-6488bd111b7a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f4776a21-6f2d-4f6d-ac32-6488bd111b7a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pairs",
              "summary": "{\n  \"name\": \"df_pairs\",\n  \"rows\": 24697,\n  \"fields\": [\n    {\n      \"column\": \"doc_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 446,\n        \"samples\": [\n          \"ann_0379\",\n          \"ann_0128\",\n          \"ann_0006\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mention1_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 204,\n        \"num_unique_values\": 201,\n        \"samples\": [\n          54,\n          17,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mention2_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 1,\n        \"max\": 205,\n        \"num_unique_values\": 201,\n        \"samples\": [\n          55,\n          18,\n          47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m1_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10012,\n        \"samples\": [\n          \"\\u0627\\u0644\\u0643\\u0634\\u0641\",\n          \"\\u0622\\u0631\\u0627\\u0645 \\u0627\\u0644\\u0623\\u0648\\u0644\",\n          \"\\u0627\\u0644\\u0639\\u0644\\u0627\\u0642\\u0627\\u062a \\u0627\\u0644\\u062b\\u0646\\u0627\\u0626\\u064a\\u0629 \\u0628\\u064a\\u0646 \\u0644\\u0628\\u0646\\u0627\\u0646 \\u0648- -\\u0643\\u0646\\u062f\\u0627\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m2_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9101,\n        \"samples\": [\n          \"\\u0627\\u0644\\u0644\\u0648\\u0627\\u0621 \\u062a\\u0648\\u0641\\u064a\\u0642 \\u0627\\u0644\\u064a\\u0627\\u0633\\u0631\\u064a \\u0627\\u0644\\u0630\\u064a {\\u0646\\u062a\\u062e\\u0628 *T*-1 *-1 \\u0646\\u0627\\u0637\\u0642\\u0627 \\u0628- -{\\u0633\\u0645 \\u0647`\\u0630\\u0627 \\u0627\\u0644\\u0645\\u062c\\u0644\\u0633\",\n          \"\\u0625\\u0631\\u062c\\u0627\\u0639 * \\u0627\\u0644\\u0643\\u0646\\u064a\\u0633\\u0629\",\n          \"\\u0627\\u0644\\u062d\\u062f\\u0648\\u062f \\u0627\\u0644\\u0644\\u0628\\u0646\\u0627\\u0646\\u064a\\u0629 - \\u0627\\u0644\\u0633\\u0648\\u0631\\u064a\\u0629\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token_distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 1,\n        \"max\": 50,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          21,\n          36,\n          43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m1_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"APPOS\",\n          \"IDENT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m2_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"APPOS\",\n          \"IDENT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_coreferent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_features_for_dl(df_pairs):\n",
        "\n",
        "    m1_type_encoder = LabelEncoder()\n",
        "    m2_type_encoder = LabelEncoder()\n",
        "\n",
        "    df_pairs['m1_type_encoded'] = m1_type_encoder.fit_transform(df_pairs['m1_type'].fillna('NONE'))\n",
        "    df_pairs['m2_type_encoded'] = m2_type_encoder.fit_transform(df_pairs['m2_type'].fillna('NONE'))\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    distance_features = ['token_distance']\n",
        "    df_pairs[distance_features] = scaler.fit_transform(df_pairs[distance_features])\n",
        "\n",
        "    train_data, test_data = train_test_split(df_pairs, test_size=0.2, random_state=42,\n",
        "                                            stratify=df_pairs['is_coreferent'])\n",
        "\n",
        "    return train_data, test_data, m1_type_encoder, m2_type_encoder, scaler\n",
        "\n",
        "train_data, test_data, m1_type_encoder, m2_type_encoder, scaler = prepare_features_for_dl(df_pairs)"
      ],
      "metadata": {
        "id": "HkABIZRPIT1F"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppression des caractéres spéciaux et normalisation des espaces"
      ],
      "metadata": {
        "id": "oHv5FX4JNfbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_for_arabert(text):\n",
        "    if isinstance(text, str):\n",
        "        text = re.sub(r'[^\\u0600-\\u06FF\\s]', ' ', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "    return \"\"\n"
      ],
      "metadata": {
        "id": "FQgcXuCTNWOL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribution des classes dans les données d'entraînement:\")\n",
        "print(df_pairs['is_coreferent'].value_counts())\n",
        "print(\"Pourcentage de coréférences:\", df_pairs['is_coreferent'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt-m1oD1lFby",
        "outputId": "422b994c-fa7f-40e1-d0bb-48f14d110a75"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution des classes dans les données d'entraînement:\n",
            "is_coreferent\n",
            "0    17010\n",
            "1     7687\n",
            "Name: count, dtype: int64\n",
            "Pourcentage de coréférences: 0.311252378831437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    max_len = 50\n",
        "    vocab_size=len(df_pairs)\n",
        "    embedding_dim = 300\n",
        "    m1_type_classes=10\n",
        "    m2_type_classes=10\n",
        "\n",
        "    input_m1_text = Input(shape=(max_len,), name='input_m1_text')\n",
        "    input_m2_text = Input(shape=(max_len,), name='input_m2_text')\n",
        "    input_m1_type = Input(shape=(1,), name='input_m1_type')\n",
        "    input_m2_type = Input(shape=(1,), name='input_m2_type')\n",
        "    input_distances = Input(shape=(1,), name='input_distances')\n",
        "\n",
        "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "\n",
        "    m1_embedding = embedding_layer(input_m1_text)\n",
        "    m2_embedding = embedding_layer(input_m2_text)\n",
        "\n",
        "    m1_embedding = Bidirectional(LSTM(128))(m1_embedding)\n",
        "    m2_embedding = Bidirectional(LSTM(128))(m2_embedding)\n",
        "\n",
        "    m1_type_embedding = Embedding(input_dim=m1_type_classes, output_dim=50,\n",
        "                                     input_length=1)(input_m1_type)\n",
        "    m2_type_embedding = Embedding(input_dim=m2_type_classes, output_dim=50,\n",
        "                                     input_length=1)(input_m2_type)\n",
        "\n",
        "    m1_type_embedding = Flatten()(m1_type_embedding)\n",
        "    m2_type_embedding = Flatten()(m2_type_embedding)\n",
        "\n",
        "    merged = Concatenate()([m1_embedding, m2_embedding, m1_type_embedding, m2_type_embedding, input_distances])\n",
        "\n",
        "    x = Dense(512, activation='relu')(merged)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid', name='output')(x)\n",
        "\n",
        "    model = Model(\n",
        "        inputs=[input_m1_text, input_m2_text, input_m1_type, input_m2_type, input_distances],\n",
        "        outputs=output\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    train_texts_m1 = [preprocess_text_for_arabert(t) for t in train_data['m1_text']]\n",
        "    train_texts_m2 = [preprocess_text_for_arabert(t) for t in train_data['m2_text']]\n",
        "    test_texts_m1 = [preprocess_text_for_arabert(t) for t in test_data['m1_text']]\n",
        "    test_texts_m2 = [preprocess_text_for_arabert(t) for t in test_data['m2_text']]\n",
        "\n",
        "    tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(train_texts_m1 + train_texts_m2)\n",
        "\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    m1_type_classes = len(m1_type_encoder.classes_)\n",
        "    m2_type_classes = len(m2_type_encoder.classes_)\n",
        "\n",
        "    max_len = 50\n",
        "    train_seq_m1 = pad_sequences(tokenizer.texts_to_sequences(train_texts_m1), maxlen=max_len, padding='post')\n",
        "    train_seq_m2 = pad_sequences(tokenizer.texts_to_sequences(train_texts_m2), maxlen=max_len, padding='post')\n",
        "    test_seq_m1 = pad_sequences(tokenizer.texts_to_sequences(test_texts_m1), maxlen=max_len, padding='post')\n",
        "    test_seq_m2 = pad_sequences(tokenizer.texts_to_sequences(test_texts_m2), maxlen=max_len, padding='post')\n",
        "\n",
        "    train_inputs = {\n",
        "        'input_m1_text': train_seq_m1,\n",
        "        'input_m2_text': train_seq_m2,\n",
        "        'input_m1_type': train_data['m1_type_encoded'].values.reshape(-1, 1),\n",
        "        'input_m2_type': train_data['m2_type_encoded'].values.reshape(-1, 1),\n",
        "        'input_distances': train_data[['token_distance']].values\n",
        "    }\n",
        "\n",
        "    train_targets = train_data['is_coreferent'].values\n",
        "\n",
        "    history = model.fit(\n",
        "        train_inputs,\n",
        "        train_targets,\n",
        "        batch_size=16,\n",
        "        epochs=10,\n",
        "        verbose=1,\n",
        "        validation_split=0.2\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E3HvvmhJ2Y-",
        "outputId": "a55acd94-ecfd-43ae-81ed-6e7cca534493"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "988/988 [==============================] - 445s 443ms/step - loss: 0.3990 - accuracy: 0.8120 - precision_1: 0.7017 - recall_1: 0.6806 - val_loss: 0.3451 - val_accuracy: 0.8454 - val_precision_1: 0.7951 - val_recall_1: 0.6979\n",
            "Epoch 2/10\n",
            "988/988 [==============================] - 352s 356ms/step - loss: 0.2891 - accuracy: 0.8736 - precision_1: 0.7915 - recall_1: 0.8019 - val_loss: 0.3432 - val_accuracy: 0.8603 - val_precision_1: 0.7775 - val_recall_1: 0.7910\n",
            "Epoch 3/10\n",
            "988/988 [==============================] - 341s 345ms/step - loss: 0.2184 - accuracy: 0.9047 - precision_1: 0.8421 - recall_1: 0.8509 - val_loss: 0.3968 - val_accuracy: 0.8598 - val_precision_1: 0.7692 - val_recall_1: 0.8044\n",
            "Epoch 4/10\n",
            "988/988 [==============================] - 340s 344ms/step - loss: 0.1824 - accuracy: 0.9203 - precision_1: 0.8699 - recall_1: 0.8726 - val_loss: 0.5035 - val_accuracy: 0.8378 - val_precision_1: 0.8132 - val_recall_1: 0.6420\n",
            "Epoch 5/10\n",
            "988/988 [==============================] - 341s 345ms/step - loss: 0.1555 - accuracy: 0.9293 - precision_1: 0.8890 - recall_1: 0.8810 - val_loss: 0.4697 - val_accuracy: 0.8497 - val_precision_1: 0.8014 - val_recall_1: 0.7066\n",
            "Epoch 6/10\n",
            "988/988 [==============================] - 355s 360ms/step - loss: 0.1443 - accuracy: 0.9350 - precision_1: 0.9005 - recall_1: 0.8877 - val_loss: 0.5312 - val_accuracy: 0.8436 - val_precision_1: 0.7677 - val_recall_1: 0.7350\n",
            "Epoch 7/10\n",
            "988/988 [==============================] - 447s 452ms/step - loss: 0.1345 - accuracy: 0.9389 - precision_1: 0.9040 - recall_1: 0.8974 - val_loss: 0.6011 - val_accuracy: 0.8499 - val_precision_1: 0.7715 - val_recall_1: 0.7563\n",
            "Epoch 8/10\n",
            "988/988 [==============================] - 378s 383ms/step - loss: 0.1258 - accuracy: 0.9434 - precision_1: 0.9086 - recall_1: 0.9080 - val_loss: 0.6364 - val_accuracy: 0.8530 - val_precision_1: 0.7804 - val_recall_1: 0.7539\n",
            "Epoch 9/10\n",
            "988/988 [==============================] - 339s 343ms/step - loss: 0.1208 - accuracy: 0.9463 - precision_1: 0.9079 - recall_1: 0.9193 - val_loss: 0.6844 - val_accuracy: 0.8413 - val_precision_1: 0.7927 - val_recall_1: 0.6845\n",
            "Epoch 10/10\n",
            "988/988 [==============================] - 340s 345ms/step - loss: 0.1176 - accuracy: 0.9475 - precision_1: 0.9104 - recall_1: 0.9205 - val_loss: 0.6927 - val_accuracy: 0.8586 - val_precision_1: 0.7852 - val_recall_1: 0.7697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model.save(\"/content/drive/MyDrive/Coref.h5\")\n",
        "\n",
        "with open('/content/drive/MyDrive/tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "with open('/content/drive/MyDrive/m1_type_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(m1_type_encoder, f)\n",
        "with open('/content/drive/MyDrive/m2_type_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(m2_type_encoder, f)\n",
        "with open('/content/drive/MyDrive/scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)"
      ],
      "metadata": {
        "id": "S2Qa4NC_Ol7B"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model.predict(test_inputs)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "print(\"\\nRapport de classification:\")\n",
        "print(classification_report(test_targets, y_pred))"
      ],
      "metadata": {
        "id": "jltQUmy1a9ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d90db9-cdc8-49b1-d394-8463904ec64f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 15s 89ms/step\n",
            "\n",
            "Rapport de classification:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      3402\n",
            "           1       0.77      0.81      0.79      1538\n",
            "\n",
            "    accuracy                           0.86      4940\n",
            "   macro avg       0.84      0.85      0.84      4940\n",
            "weighted avg       0.87      0.86      0.86      4940\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9NbwXZvXueM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import re\n",
        "\n",
        "model_name = \"CAMeL-Lab/bert-base-arabic-camelbert-msa-ner\"\n",
        "ner_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, aggregation_strategy=\"simple\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyobHKbET_PZ",
        "outputId": "4866cbbc-c398-4ad8-fcba-8be70ba13134"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-msa-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/m1_type_encoder.pkl', 'rb') as f:\n",
        "    m1_type_encoder = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/m2_type_encoder.pkl', 'rb') as f:\n",
        "    m2_type_encoder = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/scaler.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)"
      ],
      "metadata": {
        "id": "z30vu-i3UFvh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_transform(label, encoder):\n",
        "    if label in encoder.classes_:\n",
        "        return encoder.transform([label])[0]\n",
        "    else:\n",
        "        return encoder.transform([encoder.classes_[0]])[0]\n"
      ],
      "metadata": {
        "id": "w8vzFRDlUpce"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"CAMeL-Lab/bert-base-arabic-camelbert-msa-ner\"\n",
        "ner_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "def fix_scaler_warning(distance, scaler):\n",
        "    import pandas as pd\n",
        "    distance_df = pd.DataFrame([[distance]], columns=['token_distance'])\n",
        "    distance_scaled = scaler.transform(distance_df)[0][0]\n",
        "    return distance_scaled\n",
        "\n",
        "def predict_coreference_fixed(sentence, model, max_len=50):\n",
        "\n",
        "    ner_results = ner_pipeline(sentence)\n",
        "    mentions = []\n",
        "    for r in ner_results:\n",
        "        mentions.append({\n",
        "            'text': r['word'],\n",
        "            'start': r['start'],\n",
        "            'end': r['end'],\n",
        "            'label': r['entity_group']\n",
        "        })\n",
        "\n",
        "    print(f\"Mentions trouvées: {len(mentions)}\")\n",
        "    for m in mentions:\n",
        "        print(f\"- {m['text']} ({m['label']}) at {m['start']}-{m['end']}\")\n",
        "\n",
        "    if len(mentions) < 2:\n",
        "        return []\n",
        "\n",
        "    from itertools import combinations\n",
        "    mention_pairs = list(combinations(mentions, 2))\n",
        "\n",
        "    all_inputs = {\n",
        "        'input_m1_text': [],\n",
        "        'input_m2_text': [],\n",
        "        'input_m1_type': [],\n",
        "        'input_m2_type': [],\n",
        "        'input_distances': []\n",
        "    }\n",
        "\n",
        "    for m1, m2 in mention_pairs:\n",
        "        text1 = preprocess_text_for_arabert(m1['text'])\n",
        "        text2 = preprocess_text_for_arabert(m2['text'])\n",
        "\n",
        "        seq1 = tokenizer.texts_to_sequences([text1])\n",
        "        seq2 = tokenizer.texts_to_sequences([text2])\n",
        "\n",
        "        if not seq1 or not seq1[0]:\n",
        "            seq1 = [[1]]\n",
        "        if not seq2 or not seq2[0]:\n",
        "            seq2 = [[1]]\n",
        "\n",
        "        seq1_padded = pad_sequences(seq1, maxlen=max_len, padding='post')[0]\n",
        "        seq2_padded = pad_sequences(seq2, maxlen=max_len, padding='post')[0]\n",
        "\n",
        "        type1 = safe_transform(m1[\"label\"], m1_type_encoder)\n",
        "        type2 = safe_transform(m2[\"label\"], m2_type_encoder)\n",
        "\n",
        "        distance = abs(m2['start'] - m1['end'])\n",
        "        distance_scaled = fix_scaler_warning(distance, scaler)\n",
        "\n",
        "        all_inputs['input_m1_text'].append(seq1_padded)\n",
        "        all_inputs['input_m2_text'].append(seq2_padded)\n",
        "        all_inputs['input_m1_type'].append([type1])\n",
        "        all_inputs['input_m2_type'].append([type2])\n",
        "        all_inputs['input_distances'].append([distance_scaled])\n",
        "\n",
        "    for key in all_inputs:\n",
        "        all_inputs[key] = np.array(all_inputs[key])\n",
        "\n",
        "    predictions = model.predict(all_inputs, verbose=0)\n",
        "\n",
        "    coref_pairs = []\n",
        "    threshold = 0.5\n",
        "\n",
        "    for i, (m1, m2) in enumerate(mention_pairs):\n",
        "        score = predictions[i][0]\n",
        "        print(f\"Paire: '{m1['text']}' vs '{m2['text']}' -> Score: {score:.4f}\")\n",
        "\n",
        "        if score > threshold:\n",
        "            coref_pairs.append({\n",
        "                'mention1': m1,\n",
        "                'mention2': m2,\n",
        "                'score': float(score)\n",
        "            })\n",
        "\n",
        "    return coref_pairs\n",
        "\n",
        "def test_real_coreference_examples(model):\n",
        "\n",
        "    test_cases = [\n",
        "        {\n",
        "            'sentence': \"أحمد طالب ذكي. هو يدرس في الجامعة.\",\n",
        "            'expected': \"أحمد et هو devraient être coréférents\"\n",
        "        },\n",
        "\n",
        "        {\n",
        "            'sentence': \"زار محمد المتحف. محمد كان معجباً بالمعروضات.\",\n",
        "            'expected': \"Les deux occurrences de محمد devraient être coréférentes\"\n",
        "        },\n",
        "\n",
        "        {\n",
        "            'sentence': \"الطبيب فحص المريض. قال الطبيب إن الحالة جيدة.\",\n",
        "            'expected': \"Les deux occurrences de الطبيب devraient être coréférentes\"\n",
        "        },\n",
        "\n",
        "        {\n",
        "            'sentence': \"فاطمة مهندسة ماهرة. هي تعمل في شركة كبيرة.\",\n",
        "            'expected': \"فاطمة et هي devraient être coréférents\"\n",
        "        },\n",
        "\n",
        "        {\n",
        "            'sentence': \"جاء الأستاذ إلى الصف. المعلم شرح الدرس بوضوح.\",\n",
        "            'expected': \"الأستاذ et المعلم pourraient être coréférents\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TEST DE CORÉFÉRENCE AVEC EXEMPLES RÉELS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, test_case in enumerate(test_cases, 1):\n",
        "        print(f\"\\n--- Test {i} ---\")\n",
        "        print(f\"Phrase: {test_case['sentence']}\")\n",
        "        print(f\"Attendu: {test_case['expected']}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        results = predict_coreference_fixed(test_case['sentence'], model)\n",
        "\n",
        "        if results:\n",
        "            print(\"Coréférences détectées:\")\n",
        "            for r in results:\n",
        "                print(f\"  '{r['mention1']['text']}' ↔ '{r['mention2']['text']}' (score: {r['score']:.3f})\")\n",
        "        else:\n",
        "            print(\"Aucune coréférence détectée\")\n",
        "\n",
        "        print()\n",
        "\n",
        "test_real_coreference_examples(model)"
      ],
      "metadata": {
        "id": "3weFEMMlj_iK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}