{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZcrrLxR8KAXC",
        "outputId": "ba341a03-47a7-4b30-98ab-91ad1de67dfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: scipy 1.15.3\n",
            "Uninstalling scipy-1.15.3:\n",
            "  Successfully uninstalled scipy-1.15.3\n",
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-addons as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "fastai 2.7.19 requires scipy, which is not installed.\n",
            "jax 0.5.2 requires scipy>=1.11.1, which is not installed.\n",
            "scikit-learn 1.6.1 requires scipy>=1.6.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "numba 0.61.2 requires numpy<2.3,>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "071bd99788fc42219d07c30faa0763e4",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scipy==1.10.1) (1.23.5)\n",
            "Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.10.1\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.12.0)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=2.0 (from tensorflow==2.12.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.12.0)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.12.0)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.12.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-pasta, gast, jaxlib, astunparse, jax, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.4.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 libclang-18.1.1 protobuf-4.25.7 tensorboard-2.12.3 tensorboard-data-server-0.7.2 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1\n",
            "Collecting tensorflow-addons==0.20.0\n",
            "  Downloading tensorflow_addons-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons==0.20.0) (25.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==0.20.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n",
            "\u001b[33mWARNING: Skipping tf-keras as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following yanked versions: 2.20.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tf-keras==2.12.0 (from versions: 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1rc0, 2.15.1, 2.16.0rc0, 2.16.0rc1, 2.16.0rc2, 2.16.0rc3, 2.16.0rc4, 2.16.0, 2.17.0rc0, 2.17.0, 2.18.0rc0, 2.18.0, 2.19.0rc0, 2.19.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tf-keras==2.12.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting conllu\n",
            "  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading conllu-6.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-6.0.0\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.3.3\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-7f4ueqd6\n",
            "  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-7f4ueqd6\n",
            "  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n",
            "  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras_contrib==2.0.8) (2.12.0)\n",
            "Building wheels for collected packages: keras_contrib\n",
            "  Building wheel for keras_contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101058 sha256=9807793c27dd0848fa24326ae130e39582b6c1252b963f811d89d5d9676b4be5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qfmjo1hi/wheels/51/5f/dc/dade7fdf81085b847dde4bd2fa307f2e0f67a26400031d0c27\n",
            "Successfully built keras_contrib\n",
            "Installing collected packages: keras_contrib\n",
            "Successfully installed keras_contrib-2.0.8\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting camel-tools\n",
            "  Downloading camel_tools-1.5.6-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from pyarabic) (1.17.0)\n",
            "Collecting future (from camel-tools)\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting docopt (from camel-tools)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from camel-tools) (5.5.2)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from camel-tools) (1.6.1)\n",
            "Collecting dill (from camel-tools)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.6.0+cpu)\n",
            "Collecting transformers<4.44.0,>=4.0 (from camel-tools)\n",
            "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting editdistance (from camel-tools)\n",
            "  Downloading editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from camel-tools) (2.32.3)\n",
            "Collecting emoji (from camel-tools)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pyrsistent (from camel-tools)\n",
            "  Downloading pyrsistent-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting tabulate (from camel-tools)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from camel-tools) (4.67.1)\n",
            "Collecting muddler (from camel-tools)\n",
            "  Downloading muddler-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting camel-kenlm>=2025.4.8 (from camel-tools)\n",
            "  Downloading camel-kenlm-2025.4.8.zip (556 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.5/556.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->camel-tools) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->camel-tools) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.31.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.5.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers<4.44.0,>=4.0->camel-tools)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->camel-tools) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->camel-tools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->camel-tools) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->camel-tools) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->camel-tools) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->camel-tools) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->camel-tools) (3.0.2)\n",
            "Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading camel_tools-1.5.6-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading muddler-0.1.3-py3-none-any.whl (16 kB)\n",
            "Downloading pyrsistent-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (120 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: camel-kenlm, docopt\n",
            "  Building wheel for camel-kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camel-kenlm: filename=camel_kenlm-2025.4.8-cp311-cp311-linux_x86_64.whl size=3455549 sha256=3d47fac53c6fd2fdeb1510aabfc904bb1f8798fff9907b35d5e7e713e46f113e\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/b9/62/8559aee1915ae6690fcc902a972a9ba0ff46d3ee67fea2aa44\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=91c4e45968fb07ee83ac8def3f5ab3d023257b4c5328adeba00ee654b0485691\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built camel-kenlm docopt\n",
            "Installing collected packages: docopt, camel-kenlm, tabulate, pyrsistent, pyarabic, muddler, future, emoji, editdistance, dill, tokenizers, transformers, camel-tools\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "Successfully installed camel-kenlm-2025.4.8 camel-tools-1.5.6 dill-0.4.0 docopt-0.6.2 editdistance-0.8.1 emoji-2.14.1 future-1.0.0 muddler-0.1.3 pyarabic-0.6.15 pyrsistent-0.20.0 tabulate-0.9.0 tokenizers-0.19.1 transformers-4.43.4\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y scipy numpy tensorflow tensorflow-addons\n",
        "!pip install numpy==1.23.5\n",
        "!pip install scipy==1.10.1\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install tensorflow-addons==0.20.0\n",
        "!pip uninstall -y tf-keras\n",
        "!pip install tf-keras==2.12.0\n",
        "!pip install conllu\n",
        "!pip install gensim\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install pyarabic camel-tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0qhrPrU1jbg"
      },
      "source": [
        "Importation des bibliothèques nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ftp4_ZfKOlU",
        "outputId": "968c18ee-553e-4b63-f047-3e61267ef0e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import conllu\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gensim\n",
        "from gensim.downloader import load\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.layers import CRF\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense, Conv1D, Dropout, concatenate\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pyarabic.araby as araby\n",
        "from camel_tools.utils.normalize import normalize_unicode\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guG_59b81wRi"
      },
      "source": [
        "connection avec google drive pour le sauvegarde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvSWftbAKOi0",
        "outputId": "82119d66-0057-40ed-ea35-0eaaaa580b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpgrd6nnK0KM"
      },
      "source": [
        "Importation et affichage du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE_m7dzOKzbJ",
        "outputId": "8fe39ed3-1341-4b8b-f587-f8a8f4b69ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 1,\n",
              " 'form': 'لونغ',\n",
              " 'lemma': 'لُونغ',\n",
              " 'upos': 'X',\n",
              " 'xpos': 'X---------',\n",
              " 'feats': {'Foreign': 'Yes'},\n",
              " 'head': 0,\n",
              " 'deprel': 'root',\n",
              " 'deps': [('root', 0)],\n",
              " 'misc': {'Vform': 'لُونغ',\n",
              "  'Gloss': 'Long',\n",
              "  'Root': 'lUn.g',\n",
              "  'Translit': 'lūnġ',\n",
              "  'LTranslit': 'lūnġ'}}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/ar_padt-ud-dev.conllu\", mode=\"r\", encoding=\"utf-8\") as data:\n",
        "    annotations=data.read()\n",
        "\n",
        "sentences = conllu.parse(annotations)\n",
        "sentences[1][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjUMNugb103H"
      },
      "source": [
        "Création d'un DataFrame contenant l'id de la phrase, l'id des mots, le mot et son étiquette\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNB_FrdVKOc8"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "current_sentence_id = None\n",
        "\n",
        "with open(\"/content/drive/MyDrive/ar_padt-ud-dev.conllu\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "\n",
        "        if line.startswith(\"# sent_id\"):\n",
        "            current_sentence_id = line.split(\"=\")[-1].strip()\n",
        "\n",
        "        elif line and not line.startswith(\"#\"):\n",
        "            parts = line.split(\"\\t\")\n",
        "            if len(parts) >= 4 and parts[0].isdigit():\n",
        "                word_id = int(parts[0])\n",
        "                word = parts[1]\n",
        "                upos = parts[3]\n",
        "                data.append((current_sentence_id, word_id, word, upos))\n",
        "\n",
        "df1 = pd.DataFrame(data, columns=[\"sentence_id\", \"word_id\", \"w_name\", \"tag_name\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVO5Vzel2HWf"
      },
      "source": [
        "Affichage et visualisation des catégories d'étiquettes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dhu5vKsvKOZk",
        "outputId": "a472e2c4-86f0-4a6c-db4f-5634dabd722e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(0, 0, '9612'),\n",
              " Text(0, 0, '4410'),\n",
              " Text(0, 0, '2916'),\n",
              " Text(0, 0, '2882'),\n",
              " Text(0, 0, '2318'),\n",
              " Text(0, 0, '2041'),\n",
              " Text(0, 0, '2018'),\n",
              " Text(0, 0, '1211'),\n",
              " Text(0, 0, '969'),\n",
              " Text(0, 0, '625'),\n",
              " Text(0, 0, '555'),\n",
              " Text(0, 0, '270'),\n",
              " Text(0, 0, '258'),\n",
              " Text(0, 0, '108'),\n",
              " Text(0, 0, '27'),\n",
              " Text(0, 0, '18'),\n",
              " Text(0, 0, '1')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1170x827 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(11.7, 8.27)\n",
        "ax = sns.countplot(x=df1['tag_name'],order=df1['tag_name'].value_counts(ascending=False).index)\n",
        "abs_values = df1['tag_name'].value_counts(ascending=False).values\n",
        "ax.bar_label(container=ax.containers[0], labels=abs_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TM0ixjnMzoL"
      },
      "source": [
        "Fonction qui permet de supprimer le Tashkeel au mots et les signes coraniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIL9_cV8LutV"
      },
      "outputs": [],
      "source": [
        "def normalize_arabic_text(text):\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    text = normalize_unicode(text)\n",
        "\n",
        "    text = araby.strip_tashkeel(text)\n",
        "\n",
        "    text = araby.normalize_alef(text)\n",
        "\n",
        "    text = araby.normalize_hamza(text)\n",
        "\n",
        "    text = araby.normalize_ligature(text)\n",
        "\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CToTrwPKM4k1"
      },
      "source": [
        "Nettoyage (Pre-Processing) du dataset en ne gardant que les mots en arabe, en supprimant Tashkeel et on garde le POS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy8GPuAiKOPs"
      },
      "outputs": [],
      "source": [
        "grouped = df1.groupby(\"sentence_id\")\n",
        "\n",
        "corpus = []\n",
        "list_pos = []\n",
        "list_words = []\n",
        "pos = []\n",
        "list_sentences = []\n",
        "\n",
        "re_pattern = re.compile(r'[a-zA-Z]+')\n",
        "\n",
        "for sentence_id, group in grouped:\n",
        "    sentence_txt = \" \".join(group['w_name'].tolist())\n",
        "    normalized_sentence = normalize_arabic_text(sentence_txt)\n",
        "\n",
        "    if re_pattern.search(normalized_sentence) is None:\n",
        "        list_sentences.append(normalized_sentence)\n",
        "        word_dict = {}\n",
        "        pos_bfr = []\n",
        "\n",
        "        for idx, row in group.iterrows():\n",
        "            word_str = normalize_arabic_text(row['w_name'])\n",
        "            word_pos = row['tag_name']\n",
        "\n",
        "            list_words.append(word_str)\n",
        "            list_pos.append(word_pos)\n",
        "            pos_bfr.append(word_pos)\n",
        "\n",
        "            word_dict[int(row['word_id'])] = [word_str, word_pos]\n",
        "\n",
        "        corpus.append(word_dict)\n",
        "        pos.append(pos_bfr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLTq_kvi2jwm"
      },
      "source": [
        "Création du dataframe frame final aprés pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJfTUn5fMH1E"
      },
      "outputs": [],
      "source": [
        "rows = []\n",
        "\n",
        "for sentence_idx, word_dict in enumerate(corpus):\n",
        "    sentence_text = list_sentences[sentence_idx]\n",
        "    for word_id, (word_str, word_pos) in word_dict.items():\n",
        "        rows.append({\n",
        "            \"sentence_id\": sentence_idx, \n",
        "            \"w_name\": word_str,\n",
        "            \"tag_name\": word_pos,\n",
        "        })\n",
        "\n",
        "final_df = pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1c2rLyinMJWj",
        "outputId": "2d5184f5-d054-4b36-ca9d-9087d7c381ee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"final_df\",\n  \"rows\": 30239,\n  \"fields\": [\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 258,\n        \"min\": 0,\n        \"max\": 908,\n        \"num_unique_values\": 909,\n        \"samples\": [\n          866,\n          439,\n          342\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"w_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6369,\n        \"samples\": [\n          \"\\u0631\\u0628\\u0637\\u0629\",\n          \"\\u064a\\u062d\\u0627\\u0648\\u0644\",\n          \"\\u0637\\u0648\\u0643\\u064a\\u0648\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"CCONJ\",\n          \"VERB\",\n          \"NOUN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "final_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-18ea6428-0ae9-457d-843e-f4c1f84c6fbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>w_name</th>\n",
              "      <th>tag_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>و</td>\n",
              "      <td>CCONJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>قالت</td>\n",
              "      <td>VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>روث</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>شوارتز</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>التي</td>\n",
              "      <td>DET</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18ea6428-0ae9-457d-843e-f4c1f84c6fbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18ea6428-0ae9-457d-843e-f4c1f84c6fbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18ea6428-0ae9-457d-843e-f4c1f84c6fbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9d7374f3-790f-4816-912b-47e962aba649\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d7374f3-790f-4816-912b-47e962aba649')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9d7374f3-790f-4816-912b-47e962aba649 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   sentence_id  w_name tag_name\n",
              "0            0       و    CCONJ\n",
              "1            0    قالت     VERB\n",
              "2            0     روث        X\n",
              "3            0  شوارتز        X\n",
              "4            0    التي      DET"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWiuyG7z2qex"
      },
      "source": [
        "Sauvegarde du dataframe dans le drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nd_FRtaQNELI"
      },
      "outputs": [],
      "source": [
        "final_df.to_csv(\"/content/drive/MyDrive/POS_dataset.csv\", encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iWThlXb2xXw"
      },
      "source": [
        "Création de variables contenant les phrases et les étiquettes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ewBflFbVNEHk"
      },
      "outputs": [],
      "source": [
        "sentences = grouped[\"w_name\"].apply(list).tolist()\n",
        "tags = grouped[\"tag_name\"].apply(list).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV3s31AR25Pr"
      },
      "source": [
        "Encodage des mots et des étiquettes en mappant chaque mot avec son id pour faciliter leur manipulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwAyujgrNECd",
        "outputId": "8746599d-28bd-42fe-cd6c-35edc1447faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'SYM', 1: 'ADP', 2: 'PUNCT', 3: 'DET', 4: 'ADV', 5: 'NOUN', 6: 'CCONJ', 7: 'INTJ', 8: 'X', 9: 'PROPN', 10: 'VERB', 11: 'ADJ', 12: 'NUM', 13: 'PART', 14: 'AUX', 15: 'SCONJ', 16: 'PRON'}\n"
          ]
        }
      ],
      "source": [
        "word2idx = {w: i + 2 for i, w in enumerate(set(final_df[\"w_name\"]))}\n",
        "word2idx[\"UNK\"] = 1\n",
        "word2idx[\"PAD\"] = 0\n",
        "\n",
        "tag2idx = {t: i for i, t in enumerate(set(final_df[\"tag_name\"]))}\n",
        "idx2tag = {i: t for t, i in tag2idx.items()}\n",
        "n_tags = len(tag2idx)\n",
        "\n",
        "X = [[word2idx.get(w, 1) for w in s] for s in sentences]\n",
        "y = [[tag2idx[t] for t in s] for s in tags]\n",
        "\n",
        "print(idx2tag)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Tn1KXgxQA4En"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/word2idx.pkl', 'wb') as f:\n",
        "    pickle.dump(word2idx, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/idx2label.pkl', 'wb') as f:\n",
        "    pickle.dump(idx2tag, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/label2idx.pkl', 'wb') as f:\n",
        "    pickle.dump(tag2idx, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9v3-K8Zi-HM"
      },
      "outputs": [],
      "source": [
        "def extract_features(word):\n",
        "    features = []\n",
        "\n",
        "    contains_digit = [1] if any(c.isdigit() for c in word) else [0]\n",
        "    is_digit = [1] if word.isdigit() else [0]\n",
        "\n",
        "    is_punct = [1] if all(not c.isalnum() for c in word) else [0]\n",
        "\n",
        "    suffix = word[-3:].ljust(3)\n",
        "    suffix_features = [ord(c) / 1200 for c in suffix]  \n",
        "\n",
        "    prefix = word[:3].ljust(3)\n",
        "    prefix_features = [ord(c) / 1200 for c in prefix]\n",
        "\n",
        "    length = [min(len(word) / 15, 1.0)]\n",
        "    has_alef = [1] if 'ا' in word else [0]\n",
        "    has_waw = [1] if 'و' in word else [0]\n",
        "    has_yeh = [1] if 'ي' in word else [0]\n",
        "\n",
        "    features = (contains_digit + is_digit + is_punct + suffix_features +\n",
        "               prefix_features + length + has_alef + has_waw + has_yeh)\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1cN2B5qOjZhj"
      },
      "outputs": [],
      "source": [
        "def extract_features_for_sentence(sentence):\n",
        "    features = []\n",
        "    for word in sentence:\n",
        "        features.append(extract_features(word))\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFGOO0k3Y9i"
      },
      "source": [
        "Covertir toutes les sequences avec la même longueur qui est celle de la séquence la plus longue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6XIzYnPND6L"
      },
      "outputs": [],
      "source": [
        "MAXLEN = max(len(s) for s in sentences)\n",
        "X = [[word2idx.get(w, word2idx[\"UNK\"]) for w in s] for s in sentences]\n",
        "X_padded = pad_sequences(X, maxlen=MAXLEN, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "\n",
        "X_features = []\n",
        "for s in sentences:\n",
        "    sent_features = extract_features_for_sentence(s)\n",
        "    while len(sent_features) < MAXLEN:\n",
        "        zeros_vector = [0] * len(extract_features(\"\"))\n",
        "        sent_features.append(zeros_vector)\n",
        "\n",
        "    X_features.append(sent_features)\n",
        "\n",
        "X_features=np.array(X_features)\n",
        "\n",
        "y = [[tag2idx.get(t, tag2idx[\"X\"]) for t in ts] for ts in tags]\n",
        "y_padded = pad_sequences(y, maxlen=MAXLEN, padding=\"post\", value=tag2idx[\"X\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "thqjO0T-1wn3"
      },
      "outputs": [],
      "source": [
        "X_padded_train, X_padded_test, X_features_train, X_features_test, y_train, y_test = train_test_split(\n",
        "    X_padded, X_features, y_padded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_padded_train = tf.convert_to_tensor(X_padded_train)\n",
        "X_padded_test = tf.convert_to_tensor(X_padded_test)\n",
        "X_features_train = tf.convert_to_tensor(X_features_train)\n",
        "X_features_test = tf.convert_to_tensor(X_features_test)\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "y_test = tf.convert_to_tensor(y_test)\n",
        "\n",
        "y_train = tf.expand_dims(y_train, axis=-1)\n",
        "y_test = tf.expand_dims(y_test, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIerfWhGAnDM"
      },
      "source": [
        "Création du modèle BILSTTM avec une couche dense en transformant chaque vecteur en probabilité"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2p06C7y1LzP",
        "outputId": "a452856b-e63f-4ebe-e754-06c149203ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " word_input (InputLayer)        [(None, 112)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 112, 100)     637100      ['word_input[0][0]']             \n",
            "                                                                                                  \n",
            " feature_input (InputLayer)     [(None, 112, 13)]    0           []                               \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 112, 113)     0           ['embedding_4[0][0]',            \n",
            "                                                                  'feature_input[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 112, 200)    171200      ['concatenate_4[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 112, 200)     0           ['bidirectional_4[0][0]']        \n",
            "                                                                                                  \n",
            " time_distributed_4 (TimeDistri  (None, 112, 17)     3417        ['dropout_4[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 811,717\n",
            "Trainable params: 811,717\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "n_words = len(word2idx)\n",
        "n_chars = len(char2idx)\n",
        "n_features =  X_features_train.shape[2]\n",
        "\n",
        "word_input = Input(shape=(MAXLEN,), name='word_input')\n",
        "feature_input = Input(shape=(MAXLEN, n_features), name='feature_input')\n",
        "word_embedding = Embedding(input_dim=n_words, output_dim=100,input_length=MAXLEN, mask_zero=True)(word_input)\n",
        "\n",
        "merged = concatenate([word_embedding, feature_input])\n",
        "\n",
        "main_lstm = Bidirectional(LSTM(units=100, return_sequences=True))(merged)\n",
        "main_lstm = Dropout(0.5)(main_lstm)\n",
        "\n",
        "output = TimeDistributed(Dense(n_tags, activation='softmax'))(main_lstm)\n",
        "\n",
        "model = Model(inputs=[word_input, feature_input], outputs=output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7hbPlV_bHNo"
      },
      "source": [
        "Conversion des données en tableaux Numpy pour faire le split puis leur reconversion en teneur TensorFlow et finalement entrainement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNCONSc1v22j",
        "outputId": "a348e18e-e6c8-48c3-c051-481482b35d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - 17s 401ms/step - loss: 2.3171 - accuracy: 0.2910 - val_loss: 2.0176 - val_accuracy: 0.3594\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 6s 278ms/step - loss: 1.9454 - accuracy: 0.4160 - val_loss: 1.7016 - val_accuracy: 0.5395\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 6s 266ms/step - loss: 1.5606 - accuracy: 0.5552 - val_loss: 1.2478 - val_accuracy: 0.6270\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 6s 265ms/step - loss: 1.1246 - accuracy: 0.6621 - val_loss: 0.8975 - val_accuracy: 0.7113\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 6s 261ms/step - loss: 0.8172 - accuracy: 0.7531 - val_loss: 0.6710 - val_accuracy: 0.8069\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 6s 261ms/step - loss: 0.5886 - accuracy: 0.8395 - val_loss: 0.5242 - val_accuracy: 0.8594\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 6s 263ms/step - loss: 0.4382 - accuracy: 0.8914 - val_loss: 0.4325 - val_accuracy: 0.8804\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 6s 261ms/step - loss: 0.3444 - accuracy: 0.9169 - val_loss: 0.3871 - val_accuracy: 0.8924\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 6s 257ms/step - loss: 0.2812 - accuracy: 0.9309 - val_loss: 0.3585 - val_accuracy: 0.8945\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 6s 263ms/step - loss: 0.2400 - accuracy: 0.9408 - val_loss: 0.3434 - val_accuracy: 0.8971\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 6s 259ms/step - loss: 0.2108 - accuracy: 0.9466 - val_loss: 0.3363 - val_accuracy: 0.8963\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 6s 262ms/step - loss: 0.1881 - accuracy: 0.9536 - val_loss: 0.3288 - val_accuracy: 0.9007\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 6s 259ms/step - loss: 0.1695 - accuracy: 0.9591 - val_loss: 0.3338 - val_accuracy: 0.8995\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 6s 256ms/step - loss: 0.1520 - accuracy: 0.9628 - val_loss: 0.3260 - val_accuracy: 0.9009\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 6s 260ms/step - loss: 0.1378 - accuracy: 0.9651 - val_loss: 0.3279 - val_accuracy: 0.9011\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 6s 258ms/step - loss: 0.1254 - accuracy: 0.9689 - val_loss: 0.3382 - val_accuracy: 0.8999\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 6s 258ms/step - loss: 0.1170 - accuracy: 0.9704 - val_loss: 0.3315 - val_accuracy: 0.9019\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 6s 256ms/step - loss: 0.1040 - accuracy: 0.9738 - val_loss: 0.3540 - val_accuracy: 0.8985\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 6s 255ms/step - loss: 0.0942 - accuracy: 0.9770 - val_loss: 0.3540 - val_accuracy: 0.8985\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 6s 259ms/step - loss: 0.0870 - accuracy: 0.9790 - val_loss: 0.3473 - val_accuracy: 0.8995\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([X_padded_train,X_features_train], y_train, batch_size=32, epochs=20,validation_data=([X_padded_test, X_features_test], y_test),verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dO3MewfbVh_"
      },
      "source": [
        "Evaluation et sauvegarde du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gRPx0Ck1Owh",
        "outputId": "d4b7bbb1-b380-4922-f413-349e394a4c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3473 - accuracy: 0.8995\n",
            "loss: 0.3473\n",
            "accuracy: 0.8995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate([X_padded_test, X_features_test], y_test)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "    print(f\"{name}: {value:.4f}\")\n",
        "\n",
        "model.save('/content/drive/MyDrive/modele')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtG4mA4QbgAQ"
      },
      "source": [
        "Création d'un modèle BILSTM avec une couche CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HRb6Ku2w2Mz",
        "outputId": "699845c4-e00b-4011-8e25-a7bb9ff83739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " word_input (InputLayer)        [(None, 112)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 112, 100)     637100      ['word_input[0][0]']             \n",
            "                                                                                                  \n",
            " feature_input (InputLayer)     [(None, 112, 13)]    0           []                               \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 112, 113)     0           ['embedding_4[0][0]',            \n",
            "                                                                  'feature_input[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 112, 200)    171200      ['concatenate_4[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 112, 200)     0           ['bidirectional_4[0][0]']        \n",
            "                                                                                                  \n",
            " time_distributed_4 (TimeDistri  (None, 112, 17)     3417        ['dropout_4[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 811,717\n",
            "Trainable params: 811,717\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "6/6 [==============================] - 8s 822ms/step - loss: 2.6273 - accuracy: 0.6194 - val_loss: 2.1707 - val_accuracy: 0.7902\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 4s 645ms/step - loss: 1.5568 - accuracy: 0.7653 - val_loss: 0.9602 - val_accuracy: 0.7499\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 4s 608ms/step - loss: 0.8715 - accuracy: 0.7698 - val_loss: 0.7149 - val_accuracy: 0.7925\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 3s 587ms/step - loss: 0.7233 - accuracy: 0.7890 - val_loss: 0.6719 - val_accuracy: 0.7945\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 4s 588ms/step - loss: 0.6904 - accuracy: 0.7807 - val_loss: 0.6557 - val_accuracy: 0.7929\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 3s 586ms/step - loss: 0.6686 - accuracy: 0.7909 - val_loss: 0.6385 - val_accuracy: 0.7950\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 4s 589ms/step - loss: 0.6493 - accuracy: 0.7966 - val_loss: 0.6232 - val_accuracy: 0.7975\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 4s 600ms/step - loss: 0.6358 - accuracy: 0.7989 - val_loss: 0.6096 - val_accuracy: 0.8009\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 4s 602ms/step - loss: 0.6214 - accuracy: 0.8038 - val_loss: 0.5939 - val_accuracy: 0.8074\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 4s 590ms/step - loss: 0.6066 - accuracy: 0.8094 - val_loss: 0.5771 - val_accuracy: 0.8100\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 3s 570ms/step - loss: 0.5882 - accuracy: 0.8162 - val_loss: 0.5575 - val_accuracy: 0.8194\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 3s 584ms/step - loss: 0.5685 - accuracy: 0.8255 - val_loss: 0.5344 - val_accuracy: 0.8369\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 3s 588ms/step - loss: 0.5428 - accuracy: 0.8377 - val_loss: 0.5077 - val_accuracy: 0.8485\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 3s 583ms/step - loss: 0.5170 - accuracy: 0.8472 - val_loss: 0.4770 - val_accuracy: 0.8585\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 3s 599ms/step - loss: 0.4878 - accuracy: 0.8569 - val_loss: 0.4438 - val_accuracy: 0.8636\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 3s 587ms/step - loss: 0.4542 - accuracy: 0.8652 - val_loss: 0.4107 - val_accuracy: 0.8715\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 3s 579ms/step - loss: 0.4229 - accuracy: 0.8730 - val_loss: 0.3785 - val_accuracy: 0.8811\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 3s 581ms/step - loss: 0.3918 - accuracy: 0.8800 - val_loss: 0.3499 - val_accuracy: 0.8862\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 3s 585ms/step - loss: 0.3625 - accuracy: 0.8886 - val_loss: 0.3230 - val_accuracy: 0.8954\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 3s 584ms/step - loss: 0.3342 - accuracy: 0.8967 - val_loss: 0.3000 - val_accuracy: 0.9030\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 3s 580ms/step - loss: 0.3096 - accuracy: 0.9057 - val_loss: 0.2788 - val_accuracy: 0.9140\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 0.2841 - accuracy: 0.9148 - val_loss: 0.2611 - val_accuracy: 0.9206\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 3s 586ms/step - loss: 0.2633 - accuracy: 0.9217 - val_loss: 0.2439 - val_accuracy: 0.9268\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 3s 570ms/step - loss: 0.2443 - accuracy: 0.9278 - val_loss: 0.2305 - val_accuracy: 0.9313\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 3s 570ms/step - loss: 0.2229 - accuracy: 0.9352 - val_loss: 0.2172 - val_accuracy: 0.9344\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 3s 587ms/step - loss: 0.2077 - accuracy: 0.9407 - val_loss: 0.2067 - val_accuracy: 0.9367\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 3s 584ms/step - loss: 0.1911 - accuracy: 0.9457 - val_loss: 0.1968 - val_accuracy: 0.9395\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 3s 583ms/step - loss: 0.1776 - accuracy: 0.9495 - val_loss: 0.1894 - val_accuracy: 0.9421\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 0.1629 - accuracy: 0.9541 - val_loss: 0.1825 - val_accuracy: 0.9447\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 0.1527 - accuracy: 0.9576 - val_loss: 0.1771 - val_accuracy: 0.9460\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 3s 585ms/step - loss: 0.1435 - accuracy: 0.9598 - val_loss: 0.1715 - val_accuracy: 0.9483\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 3s 585ms/step - loss: 0.1333 - accuracy: 0.9640 - val_loss: 0.1674 - val_accuracy: 0.9495\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 0.1236 - accuracy: 0.9665 - val_loss: 0.1638 - val_accuracy: 0.9517\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 3s 584ms/step - loss: 0.1164 - accuracy: 0.9678 - val_loss: 0.1618 - val_accuracy: 0.9532\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 3s 583ms/step - loss: 0.1084 - accuracy: 0.9704 - val_loss: 0.1581 - val_accuracy: 0.9551\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 3s 581ms/step - loss: 0.1016 - accuracy: 0.9731 - val_loss: 0.1576 - val_accuracy: 0.9556\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 3s 580ms/step - loss: 0.0978 - accuracy: 0.9741 - val_loss: 0.1550 - val_accuracy: 0.9569\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 3s 584ms/step - loss: 0.0915 - accuracy: 0.9763 - val_loss: 0.1539 - val_accuracy: 0.9578\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 3s 585ms/step - loss: 0.0869 - accuracy: 0.9775 - val_loss: 0.1528 - val_accuracy: 0.9579\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 3s 578ms/step - loss: 0.0816 - accuracy: 0.9790 - val_loss: 0.1518 - val_accuracy: 0.9590\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 3s 581ms/step - loss: 0.0767 - accuracy: 0.9805 - val_loss: 0.1502 - val_accuracy: 0.9598\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 3s 582ms/step - loss: 0.0732 - accuracy: 0.9811 - val_loss: 0.1515 - val_accuracy: 0.9603\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 3s 571ms/step - loss: 0.0714 - accuracy: 0.9821 - val_loss: 0.1510 - val_accuracy: 0.9609\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 0.0658 - accuracy: 0.9843 - val_loss: 0.1500 - val_accuracy: 0.9614\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 3s 579ms/step - loss: 0.0622 - accuracy: 0.9848 - val_loss: 0.1493 - val_accuracy: 0.9615\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 0.0612 - accuracy: 0.9849 - val_loss: 0.1531 - val_accuracy: 0.9613\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 3s 568ms/step - loss: 0.0584 - accuracy: 0.9859 - val_loss: 0.1518 - val_accuracy: 0.9619\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 0.0556 - accuracy: 0.9868 - val_loss: 0.1503 - val_accuracy: 0.9615\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 3s 567ms/step - loss: 0.0550 - accuracy: 0.9864 - val_loss: 0.1524 - val_accuracy: 0.9618\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 3s 586ms/step - loss: 0.0524 - accuracy: 0.9871 - val_loss: 0.1518 - val_accuracy: 0.9622\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1413 - accuracy: 0.9636\n",
            "loss: 0.1413\n",
            "accuracy: 0.9636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "\n",
        "n_words = len(word2idx)\n",
        "n_chars = len(char2idx)\n",
        "n_features =  X_features_train.shape[2]\n",
        "\n",
        "word_input = Input(shape=(MAXLEN,), name='word_input')\n",
        "feature_input = Input(shape=(MAXLEN, n_features), name='feature_input')\n",
        "word_embedding = Embedding(input_dim=n_words, output_dim=100,input_length=MAXLEN, mask_zero=True)(word_input)\n",
        "\n",
        "merged = concatenate([word_embedding, feature_input])\n",
        "\n",
        "cnn_layer = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu')(merged)\n",
        "cnn_layer = Dropout(0.3)(cnn_layer)\n",
        "\n",
        "main_lstm = Bidirectional(LSTM(units=100, return_sequences=True))(cnn_layer)\n",
        "main_lstm = Dropout(0.5)(main_lstm)\n",
        "\n",
        "output = TimeDistributed(Dense(n_tags, activation='softmax'))(main_lstm)\n",
        "\n",
        "model1 = Model(inputs=[word_input, feature_input], outputs=output)\n",
        "\n",
        "model1.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "history = model1.fit(\n",
        "    [X_padded_train,X_features_train],\n",
        "    np.array(y_train),\n",
        "    batch_size=100,\n",
        "    epochs=50,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "results = model1.evaluate([X_padded_test,X_features_test], y_test)\n",
        "for name, value in zip(model1.metrics_names, results):\n",
        "    print(f\"{name}: {value:.4f}\")\n",
        "\n",
        "model1.save('/content/drive/MyDrive/modele_BILSTM-CNN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QpqutRb6joJ",
        "outputId": "b8849062-c7e9-4f4a-80d8-4fa602e2b9f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(['VERB', 'NOUN', 'NOUN', 'ADP', 'NUM', 'ADP', 'NUM', 'NOUN', 'ADJ'],\n",
              " ['ارتفع', 'سعر', 'النفط', 'بنسبة', '5%', 'خلال', '30', 'يوما', 'الماضية'])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def predict_pos_tags(sentence, model, word2idx, tag2idx, extract_features_for_sentence, extract_features, MAXLEN):\n",
        "    idx2tag = {v: k for k, v in tag2idx.items()}\n",
        "\n",
        "    words = sentence.split()\n",
        "\n",
        "    X = [word2idx.get(w, word2idx.get(\"UNK\", 0)) for w in words]\n",
        "    X_padded = pad_sequences([X], maxlen=MAXLEN, padding=\"post\", value=word2idx.get(\"PAD\", 0))\n",
        "\n",
        "    sent_features = extract_features_for_sentence(words)\n",
        "\n",
        "    while len(sent_features) < MAXLEN:\n",
        "        zeros_vector = [0] * len(extract_features(\"\"))\n",
        "        sent_features.append(zeros_vector)\n",
        "\n",
        "    X_features = np.array([sent_features])\n",
        "\n",
        "    predictions = model.predict([X_padded, X_features])\n",
        "\n",
        "    pred_tags = []\n",
        "    for i in range(min(len(words), MAXLEN)):\n",
        "        pred_idx = np.argmax(predictions[0, i])\n",
        "        if pred_idx in idx2tag:\n",
        "            pred_tags.append(idx2tag[pred_idx])\n",
        "        else:\n",
        "            pred_tags.append(tag2idx.get(\"X\", \"UNK\"))\n",
        "\n",
        "    return pred_tags, words\n",
        "sentence=\"ارتفع سعر النفط بنسبة 5% خلال 30 يوما الماضية\"\n",
        "predict_pos_tags(sentence,model1,word2idx,tag2idx,extract_features_for_sentence,extract_features,MAXLEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5tzZUuBbok8"
      },
      "source": [
        "Fine-tunning du modèle AraBert sur noss données pour la tâche de POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "Ry7MAnTkzBC1",
        "outputId": "7836a170-8e61-483a-c209-c31f19f4b696"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-52-8f362534a147>:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4530' max='4530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4530/4530 2:24:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.326300</td>\n",
              "      <td>0.349474</td>\n",
              "      <td>0.914596</td>\n",
              "      <td>0.913118</td>\n",
              "      <td>0.914472</td>\n",
              "      <td>0.914596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.217600</td>\n",
              "      <td>0.317782</td>\n",
              "      <td>0.932287</td>\n",
              "      <td>0.931228</td>\n",
              "      <td>0.932714</td>\n",
              "      <td>0.932287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.159000</td>\n",
              "      <td>0.267251</td>\n",
              "      <td>0.938711</td>\n",
              "      <td>0.937873</td>\n",
              "      <td>0.938593</td>\n",
              "      <td>0.938711</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Évaluation du modèle sur l'ensemble de validation:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [378/378 02:06]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9387\n",
            "F1 score: 0.9379\n",
            "Precision: 0.9386\n",
            "Recall: 0.9387\n",
            "Loss: 0.2673\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ARABERT_Tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ARABERT_Tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ARABERT_Tokenizer/vocab.txt',\n",
              " '/content/drive/MyDrive/ARABERT_Tokenizer/added_tokens.json',\n",
              " '/content/drive/MyDrive/ARABERT_Tokenizer/tokenizer.json')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class POSTaggingDataset(Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "def tokenize_and_align_labels(texts, tags, tokenizer):\n",
        "    tokenized_inputs = tokenizer(texts, truncation=True, padding=True, is_split_into_words=False)\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    for i, (text, tag) in enumerate(zip(texts, tags)):\n",
        "        word_ids = tokenizer(text, truncation=True, is_split_into_words=False).word_ids()\n",
        "\n",
        "        label = tag\n",
        "        label_ids = [-100] * len(tokenized_inputs.input_ids[i])  \n",
        "\n",
        "        for j in range(len(word_ids)):\n",
        "            if j < len(tokenized_inputs.input_ids[i]) and word_ids[j] is not None:\n",
        "                label_ids[j] = label\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "\n",
        "    true_predictions = [\n",
        "        [idx2tag[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [idx2tag[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    flat_predictions = [p for sublist in true_predictions for p in sublist]\n",
        "    flat_labels = [l for sublist in true_labels for l in sublist]\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(flat_labels, flat_predictions, average='weighted')\n",
        "    acc = accuracy_score(flat_labels, flat_predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\")\n",
        "\n",
        "train_df, validation_df = train_test_split(final_df, test_size=0.2, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validation_df = validation_df.reset_index(drop=True)\n",
        "\n",
        "train_texts = train_df[\"w_name\"].tolist()\n",
        "train_tags = [tag2idx[tag] for tag in train_df[\"tag_name\"].tolist()]\n",
        "\n",
        "validation_texts = validation_df[\"w_name\"].tolist()\n",
        "validation_tags = [tag2idx[tag] for tag in validation_df[\"tag_name\"].tolist()]\n",
        "\n",
        "train_encodings = tokenize_and_align_labels(train_texts, train_tags, tokenizer)\n",
        "validation_encodings = tokenize_and_align_labels(validation_texts, validation_tags, tokenizer)\n",
        "\n",
        "train_dataset = POSTaggingDataset({k: v for k, v in train_encodings.items() if k != \"labels\"}, train_encodings[\"labels\"])\n",
        "validation_dataset = POSTaggingDataset({k: v for k, v in validation_encodings.items() if k != \"labels\"}, validation_encodings[\"labels\"])\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./arabert-pos-tagger\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.1,\n",
        "    save_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"aubmindlab/bert-base-arabert\",\n",
        "    num_labels=n_tags,\n",
        "    id2label=idx2tag,\n",
        "    label2id=tag2idx\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "print(\"\\nÉvaluation du modèle sur l'ensemble de validation:\")\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1 score: {eval_results['eval_f1']:.4f}\")\n",
        "print(f\"Precision: {eval_results['eval_precision']:.4f}\")\n",
        "print(f\"Recall: {eval_results['eval_recall']:.4f}\")\n",
        "print(f\"Loss: {eval_results['eval_loss']:.4f}\")\n",
        "trainer.save_model(\"/content/drive/MyDrive/ARABERT_MODELE\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/ARABERT_Tokenizer\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
